{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8433dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b1bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>...</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "      <th>OH_B.E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Au3M-Ni</td>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>737.1</td>\n",
       "      <td>121</td>\n",
       "      <td>149</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.24</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.496072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Au3M-Zn</td>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.33</td>\n",
       "      <td>906.4</td>\n",
       "      <td>122</td>\n",
       "      <td>142</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>1.398238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Au3M-Ru</td>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>710.2</td>\n",
       "      <td>126</td>\n",
       "      <td>178</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.65</td>\n",
       "      <td>101.3</td>\n",
       "      <td>1.372716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Au3M-Rh</td>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.98</td>\n",
       "      <td>719.7</td>\n",
       "      <td>135</td>\n",
       "      <td>173</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.20</td>\n",
       "      <td>109.7</td>\n",
       "      <td>1.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Au3M-Pd</td>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>804.4</td>\n",
       "      <td>131</td>\n",
       "      <td>169</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.47</td>\n",
       "      <td>53.7</td>\n",
       "      <td>1.484960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Re-Re3M-Ta</td>\n",
       "      <td>75</td>\n",
       "      <td>186.21</td>\n",
       "      <td>21.02</td>\n",
       "      <td>3459.00</td>\n",
       "      <td>5869</td>\n",
       "      <td>33.0</td>\n",
       "      <td>776</td>\n",
       "      <td>705</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.34</td>\n",
       "      <td>761.0</td>\n",
       "      <td>170</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-0.240743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Re-Re3M-W</td>\n",
       "      <td>75</td>\n",
       "      <td>186.21</td>\n",
       "      <td>21.02</td>\n",
       "      <td>3459.00</td>\n",
       "      <td>5869</td>\n",
       "      <td>33.0</td>\n",
       "      <td>776</td>\n",
       "      <td>705</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.36</td>\n",
       "      <td>3.23</td>\n",
       "      <td>770.0</td>\n",
       "      <td>162</td>\n",
       "      <td>193</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.45</td>\n",
       "      <td>78.6</td>\n",
       "      <td>-0.193473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Re-Re3M-Os</td>\n",
       "      <td>75</td>\n",
       "      <td>186.21</td>\n",
       "      <td>21.02</td>\n",
       "      <td>3459.00</td>\n",
       "      <td>5869</td>\n",
       "      <td>33.0</td>\n",
       "      <td>776</td>\n",
       "      <td>705</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.0</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.93</td>\n",
       "      <td>106.1</td>\n",
       "      <td>0.087294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Re-Re3M-Ir</td>\n",
       "      <td>75</td>\n",
       "      <td>186.21</td>\n",
       "      <td>21.02</td>\n",
       "      <td>3459.00</td>\n",
       "      <td>5869</td>\n",
       "      <td>33.0</td>\n",
       "      <td>776</td>\n",
       "      <td>705</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.0</td>\n",
       "      <td>137</td>\n",
       "      <td>180</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.76</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Re-Re3M-Pt</td>\n",
       "      <td>75</td>\n",
       "      <td>186.21</td>\n",
       "      <td>21.02</td>\n",
       "      <td>3459.00</td>\n",
       "      <td>5869</td>\n",
       "      <td>33.0</td>\n",
       "      <td>776</td>\n",
       "      <td>705</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.0</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.97</td>\n",
       "      <td>205.3</td>\n",
       "      <td>-0.062437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Element  M-At No.  M-At wt.  M-Density    M-M.P  M-B.P  M-Enth.fus  \\\n",
       "0       Au3M-Ni        79    196.96      19.30  1337.33   3129        12.5   \n",
       "1       Au3M-Zn        79    196.96      19.30  1337.33   3129        12.5   \n",
       "2       Au3M-Ru        79    196.96      19.30  1337.33   3129        12.5   \n",
       "3       Au3M-Rh        79    196.96      19.30  1337.33   3129        12.5   \n",
       "4       Au3M-Pd        79    196.96      19.30  1337.33   3129        12.5   \n",
       "..          ...       ...       ...        ...      ...    ...         ...   \n",
       "337  Re-Re3M-Ta        75    186.21      21.02  3459.00   5869        33.0   \n",
       "338   Re-Re3M-W        75    186.21      21.02  3459.00   5869        33.0   \n",
       "339  Re-Re3M-Os        75    186.21      21.02  3459.00   5869        33.0   \n",
       "340  Re-Re3M-Ir        75    186.21      21.02  3459.00   5869        33.0   \n",
       "341  Re-Re3M-Pt        75    186.21      21.02  3459.00   5869        33.0   \n",
       "\n",
       "     M-Enth.atom  M-Enth.vap  M-Sp.ht Cap  ...  Elec.-ve  Surface.E  \\\n",
       "0            368         330        129.1  ...      1.91       1.92   \n",
       "1            368         330        129.1  ...      1.65       0.33   \n",
       "2            368         330        129.1  ...      2.20       2.60   \n",
       "3            368         330        129.1  ...      2.28       1.98   \n",
       "4            368         330        129.1  ...      2.20       1.36   \n",
       "..           ...         ...          ...  ...       ...        ...   \n",
       "337          776         705        137.0  ...      1.50       2.34   \n",
       "338          776         705        137.0  ...      2.36       3.23   \n",
       "339          776         705        137.0  ...      2.20       2.95   \n",
       "340          776         705        137.0  ...      2.20       2.36   \n",
       "341          776         705        137.0  ...      2.28       1.49   \n",
       "\n",
       "     1st Ion E  cova .radii  At.radii  Group  Period  Work F.  Elec.Aff  \\\n",
       "0        737.1          121       149   10.0       4     5.24     112.0   \n",
       "1        906.4          122       142   12.0       4     3.63     -58.0   \n",
       "2        710.2          126       178    8.0       5     4.65     101.3   \n",
       "3        719.7          135       173    9.0       5     5.20     109.7   \n",
       "4        804.4          131       169   10.0       5     5.47      53.7   \n",
       "..         ...          ...       ...    ...     ...      ...       ...   \n",
       "337      761.0          170       200    5.0       6     4.00      31.0   \n",
       "338      770.0          162       193    6.0       6     4.45      78.6   \n",
       "339      840.0          128       185    8.0       6     5.93     106.1   \n",
       "340      880.0          137       180    9.0       6     5.76     151.0   \n",
       "341      870.0          136       177   10.0       6     5.97     205.3   \n",
       "\n",
       "       OH_B.E  \n",
       "0    1.496072  \n",
       "1    1.398238  \n",
       "2    1.372716  \n",
       "3    1.527600  \n",
       "4    1.484960  \n",
       "..        ...  \n",
       "337 -0.240743  \n",
       "338 -0.193473  \n",
       "339  0.087294  \n",
       "340  0.001003  \n",
       "341 -0.062437  \n",
       "\n",
       "[342 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Dataset_A3B_OH_343.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900236db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>...</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "      <th>OH_B.E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>737.10</td>\n",
       "      <td>121</td>\n",
       "      <td>149</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.24</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.496072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.33</td>\n",
       "      <td>906.40</td>\n",
       "      <td>122</td>\n",
       "      <td>142</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>1.398238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>710.20</td>\n",
       "      <td>126</td>\n",
       "      <td>178</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.65</td>\n",
       "      <td>101.3</td>\n",
       "      <td>1.372716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.98</td>\n",
       "      <td>719.70</td>\n",
       "      <td>135</td>\n",
       "      <td>173</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.20</td>\n",
       "      <td>109.7</td>\n",
       "      <td>1.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>196.96</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>3129</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>330</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>804.40</td>\n",
       "      <td>131</td>\n",
       "      <td>169</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.47</td>\n",
       "      <td>53.7</td>\n",
       "      <td>1.484960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.57</td>\n",
       "      <td>760.00</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.72</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.704786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.00</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.93</td>\n",
       "      <td>106.1</td>\n",
       "      <td>0.679329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.00</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.97</td>\n",
       "      <td>205.3</td>\n",
       "      <td>0.531434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>136</td>\n",
       "      <td>174</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.41</td>\n",
       "      <td>222.8</td>\n",
       "      <td>0.523295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>703.00</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.34</td>\n",
       "      <td>91.2</td>\n",
       "      <td>0.291225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    M-At No.  M-At wt.  M-Density    M-M.P  M-B.P  M-Enth.fus  M-Enth.atom  \\\n",
       "0         79    196.96      19.30  1337.33   3129        12.5          368   \n",
       "1         79    196.96      19.30  1337.33   3129        12.5          368   \n",
       "2         79    196.96      19.30  1337.33   3129        12.5          368   \n",
       "3         79    196.96      19.30  1337.33   3129        12.5          368   \n",
       "4         79    196.96      19.30  1337.33   3129        12.5          368   \n",
       "..       ...       ...        ...      ...    ...         ...          ...   \n",
       "64        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "65        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "66        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "67        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "68        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "\n",
       "    M-Enth.vap  M-Sp.ht Cap  M-Elec.-ve  ...  Elec.-ve  Surface.E  1st Ion E  \\\n",
       "0          330        129.1        2.54  ...      1.91       1.92     737.10   \n",
       "1          330        129.1        2.54  ...      1.65       0.33     906.40   \n",
       "2          330        129.1        2.54  ...      2.20       2.60     710.20   \n",
       "3          330        129.1        2.54  ...      2.28       1.98     719.70   \n",
       "4          330        129.1        2.54  ...      2.20       1.36     804.40   \n",
       "..         ...          ...         ...  ...       ...        ...        ...   \n",
       "64         560        131.0        2.20  ...      1.90       2.57     760.00   \n",
       "65         560        131.0        2.20  ...      2.20       2.95     840.00   \n",
       "66         560        131.0        2.20  ...      2.28       1.49     870.00   \n",
       "67         560        131.0        2.20  ...      2.54       0.74     890.13   \n",
       "68         560        131.0        2.20  ...      2.02       0.17     703.00   \n",
       "\n",
       "    cova .radii  At.radii  Group  Period  Work F.  Elec.Aff    OH_B.E  \n",
       "0           121       149   10.0       4     5.24     112.0  1.496072  \n",
       "1           122       142   12.0       4     3.63     -58.0  1.398238  \n",
       "2           126       178    8.0       5     4.65     101.3  1.372716  \n",
       "3           135       173    9.0       5     5.20     109.7  1.527600  \n",
       "4           131       169   10.0       5     5.47      53.7  1.484960  \n",
       "..          ...       ...    ...     ...      ...       ...       ...  \n",
       "64          159       188    7.0       6     4.72      14.5  0.704786  \n",
       "65          128       185    8.0       6     5.93     106.1  0.679329  \n",
       "66          136       177   10.0       6     5.97     205.3  0.531434  \n",
       "67          136       174   11.0       6     5.41     222.8  0.523295  \n",
       "68          148       143   15.0       6     4.34      91.2  0.291225  \n",
       "\n",
       "[69 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.iloc[0:69,1:38]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc4165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M-At No.', 'M-At wt.', 'M-Density', 'M-M.P', 'M-B.P', 'M-Enth.fus', 'M-Enth.atom', 'M-Enth.vap', 'M-Sp.ht Cap', 'M-Elec.-ve', 'M-Surface.E', 'M-1st Ion E', 'M-cova .radii', 'M-At.radii', 'M-Group', 'M-Period', 'M-Work F.', 'M-Elec.Aff', 'At No.', 'At wt.', 'Density', 'M.P', 'B.P', 'Enth.fus', 'Enth.atom', 'Enth.vap', 'Sp.ht Cap', 'Elec.-ve', 'Surface.E', '1st Ion E', 'cova .radii', 'At.radii', 'Group', 'Period', 'Work F.', 'Elec.Aff', 'OH_B.E']\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d45ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df2\n",
    "y= df2['OH_B.E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d9d8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 37), (21, 37))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e17648",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b9dc1e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>M-Surface.E</th>\n",
       "      <th>M-1st Ion E</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Work F.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>1.91</td>\n",
       "      <td>149</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>1.65</td>\n",
       "      <td>142</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>2.20</td>\n",
       "      <td>178</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>2.28</td>\n",
       "      <td>173</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>2.20</td>\n",
       "      <td>169</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>188</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.54</td>\n",
       "      <td>174</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>143</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    M-At No.    M-M.P  M-Enth.fus  M-Elec.-ve  M-Surface.E  M-1st Ion E  \\\n",
       "0         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "1         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "2         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "3         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "4         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "..       ...      ...         ...         ...          ...          ...   \n",
       "64        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "65        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "66        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "67        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "68        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "\n",
       "    Elec.-ve  At.radii  Group  Work F.  \n",
       "0       1.91       149   10.0     5.24  \n",
       "1       1.65       142   12.0     3.63  \n",
       "2       2.20       178    8.0     4.65  \n",
       "3       2.28       173    9.0     5.20  \n",
       "4       2.20       169   10.0     5.47  \n",
       "..       ...       ...    ...      ...  \n",
       "64      1.90       188    7.0     4.72  \n",
       "65      2.20       185    8.0     5.93  \n",
       "66      2.28       177   10.0     5.97  \n",
       "67      2.54       174   11.0     5.41  \n",
       "68      2.02       143   15.0     4.34  \n",
       "\n",
       "[69 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.drop(labels=['M-At wt.', 'M-Density', \n",
    "                        'M-B.P', 'M-Enth.atom', \n",
    "                       'M-Enth.vap', 'M-Sp.ht Cap', 'M-cova .radii', \n",
    "                       'M-At.radii', 'M-Group', 'M-Period', 'M-Work F.', \n",
    "                       'M-Elec.Aff', 'At No.', 'At wt.', 'Density', 'M.P', \n",
    "                       'B.P', 'Enth.fus', 'Enth.atom', 'Enth.vap', \n",
    "                       'Sp.ht Cap', 'Surface.E', '1st Ion E', \n",
    "                       'cova .radii', 'Period', \n",
    "                    'Elec.Aff','OH_B.E'], axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaef50f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "cor = df3.corr()\n",
    "G=sns.heatmap(cor,annot=True,cmap=\"RdYlBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b131806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component_1</th>\n",
       "      <th>Component_2</th>\n",
       "      <th>Component_3</th>\n",
       "      <th>Component_4</th>\n",
       "      <th>Component_5</th>\n",
       "      <th>Component_6</th>\n",
       "      <th>Component_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.915967</td>\n",
       "      <td>-0.943504</td>\n",
       "      <td>-0.132418</td>\n",
       "      <td>-2.965627</td>\n",
       "      <td>-0.757080</td>\n",
       "      <td>1.676332</td>\n",
       "      <td>-0.241277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.982287</td>\n",
       "      <td>-2.807176</td>\n",
       "      <td>-1.550395</td>\n",
       "      <td>-1.175395</td>\n",
       "      <td>-1.854209</td>\n",
       "      <td>0.716056</td>\n",
       "      <td>2.623544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.493640</td>\n",
       "      <td>1.231400</td>\n",
       "      <td>-0.433444</td>\n",
       "      <td>-3.414539</td>\n",
       "      <td>0.382485</td>\n",
       "      <td>1.612778</td>\n",
       "      <td>0.029696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143799</td>\n",
       "      <td>0.748347</td>\n",
       "      <td>-1.020538</td>\n",
       "      <td>-2.591706</td>\n",
       "      <td>0.318120</td>\n",
       "      <td>1.735927</td>\n",
       "      <td>0.103422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.073746</td>\n",
       "      <td>-0.062325</td>\n",
       "      <td>-1.628189</td>\n",
       "      <td>-1.860067</td>\n",
       "      <td>-0.483666</td>\n",
       "      <td>1.302271</td>\n",
       "      <td>1.168488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.035730</td>\n",
       "      <td>1.600901</td>\n",
       "      <td>-0.101576</td>\n",
       "      <td>-1.242366</td>\n",
       "      <td>1.994269</td>\n",
       "      <td>-1.164954</td>\n",
       "      <td>0.754653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5.000112</td>\n",
       "      <td>1.739273</td>\n",
       "      <td>-0.376168</td>\n",
       "      <td>-1.336674</td>\n",
       "      <td>-0.145249</td>\n",
       "      <td>-1.331400</td>\n",
       "      <td>-0.041956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3.448784</td>\n",
       "      <td>0.669767</td>\n",
       "      <td>-1.917558</td>\n",
       "      <td>0.701586</td>\n",
       "      <td>-1.046711</td>\n",
       "      <td>-0.725332</td>\n",
       "      <td>-0.921569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2.154261</td>\n",
       "      <td>-0.362528</td>\n",
       "      <td>-2.801696</td>\n",
       "      <td>1.947625</td>\n",
       "      <td>-1.679727</td>\n",
       "      <td>-0.625285</td>\n",
       "      <td>-0.861799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.420776</td>\n",
       "      <td>-2.170906</td>\n",
       "      <td>-3.034649</td>\n",
       "      <td>3.080016</td>\n",
       "      <td>0.233897</td>\n",
       "      <td>-0.522914</td>\n",
       "      <td>0.358786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Component_1  Component_2  Component_3  Component_4  Component_5  \\\n",
       "0     -1.915967    -0.943504    -0.132418    -2.965627    -0.757080   \n",
       "1     -3.982287    -2.807176    -1.550395    -1.175395    -1.854209   \n",
       "2      0.493640     1.231400    -0.433444    -3.414539     0.382485   \n",
       "3     -0.143799     0.748347    -1.020538    -2.591706     0.318120   \n",
       "4     -1.073746    -0.062325    -1.628189    -1.860067    -0.483666   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "64     5.035730     1.600901    -0.101576    -1.242366     1.994269   \n",
       "65     5.000112     1.739273    -0.376168    -1.336674    -0.145249   \n",
       "66     3.448784     0.669767    -1.917558     0.701586    -1.046711   \n",
       "67     2.154261    -0.362528    -2.801696     1.947625    -1.679727   \n",
       "68     0.420776    -2.170906    -3.034649     3.080016     0.233897   \n",
       "\n",
       "    Component_6  Component_7  \n",
       "0      1.676332    -0.241277  \n",
       "1      0.716056     2.623544  \n",
       "2      1.612778     0.029696  \n",
       "3      1.735927     0.103422  \n",
       "4      1.302271     1.168488  \n",
       "..          ...          ...  \n",
       "64    -1.164954     0.754653  \n",
       "65    -1.331400    -0.041956  \n",
       "66    -0.725332    -0.921569  \n",
       "67    -0.625285    -0.861799  \n",
       "68    -0.522914     0.358786  \n",
       "\n",
       "[69 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_df = pd.read_csv('PCA_add_7.csv')\n",
    "PCA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ffee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df3, PCA_df], axis=1)\n",
    "df4 = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a19f55bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>M-Surface.E</th>\n",
       "      <th>M-1st Ion E</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Component_1</th>\n",
       "      <th>Component_2</th>\n",
       "      <th>Component_3</th>\n",
       "      <th>Component_4</th>\n",
       "      <th>Component_5</th>\n",
       "      <th>Component_6</th>\n",
       "      <th>Component_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>1.91</td>\n",
       "      <td>149</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>-1.915967</td>\n",
       "      <td>-0.943504</td>\n",
       "      <td>-0.132418</td>\n",
       "      <td>-2.965627</td>\n",
       "      <td>-0.757080</td>\n",
       "      <td>1.676332</td>\n",
       "      <td>-0.241277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>1.65</td>\n",
       "      <td>142</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-3.982287</td>\n",
       "      <td>-2.807176</td>\n",
       "      <td>-1.550395</td>\n",
       "      <td>-1.175395</td>\n",
       "      <td>-1.854209</td>\n",
       "      <td>0.716056</td>\n",
       "      <td>2.623544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>2.20</td>\n",
       "      <td>178</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.493640</td>\n",
       "      <td>1.231400</td>\n",
       "      <td>-0.433444</td>\n",
       "      <td>-3.414539</td>\n",
       "      <td>0.382485</td>\n",
       "      <td>1.612778</td>\n",
       "      <td>0.029696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>2.28</td>\n",
       "      <td>173</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.20</td>\n",
       "      <td>-0.143799</td>\n",
       "      <td>0.748347</td>\n",
       "      <td>-1.020538</td>\n",
       "      <td>-2.591706</td>\n",
       "      <td>0.318120</td>\n",
       "      <td>1.735927</td>\n",
       "      <td>0.103422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>1337.33</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>2.20</td>\n",
       "      <td>169</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.47</td>\n",
       "      <td>-1.073746</td>\n",
       "      <td>-0.062325</td>\n",
       "      <td>-1.628189</td>\n",
       "      <td>-1.860067</td>\n",
       "      <td>-0.483666</td>\n",
       "      <td>1.302271</td>\n",
       "      <td>1.168488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>188</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.72</td>\n",
       "      <td>5.035730</td>\n",
       "      <td>1.600901</td>\n",
       "      <td>-0.101576</td>\n",
       "      <td>-1.242366</td>\n",
       "      <td>1.994269</td>\n",
       "      <td>-1.164954</td>\n",
       "      <td>0.754653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.93</td>\n",
       "      <td>5.000112</td>\n",
       "      <td>1.739273</td>\n",
       "      <td>-0.376168</td>\n",
       "      <td>-1.336674</td>\n",
       "      <td>-0.145249</td>\n",
       "      <td>-1.331400</td>\n",
       "      <td>-0.041956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.97</td>\n",
       "      <td>3.448784</td>\n",
       "      <td>0.669767</td>\n",
       "      <td>-1.917558</td>\n",
       "      <td>0.701586</td>\n",
       "      <td>-1.046711</td>\n",
       "      <td>-0.725332</td>\n",
       "      <td>-0.921569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.54</td>\n",
       "      <td>174</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.41</td>\n",
       "      <td>2.154261</td>\n",
       "      <td>-0.362528</td>\n",
       "      <td>-2.801696</td>\n",
       "      <td>1.947625</td>\n",
       "      <td>-1.679727</td>\n",
       "      <td>-0.625285</td>\n",
       "      <td>-0.861799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>77</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>143</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.420776</td>\n",
       "      <td>-2.170906</td>\n",
       "      <td>-3.034649</td>\n",
       "      <td>3.080016</td>\n",
       "      <td>0.233897</td>\n",
       "      <td>-0.522914</td>\n",
       "      <td>0.358786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    M-At No.    M-M.P  M-Enth.fus  M-Elec.-ve  M-Surface.E  M-1st Ion E  \\\n",
       "0         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "1         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "2         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "3         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "4         79  1337.33        12.5        2.54         0.74       890.13   \n",
       "..       ...      ...         ...         ...          ...          ...   \n",
       "64        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "65        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "66        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "67        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "68        77  2739.00        26.0        2.20         2.36       880.00   \n",
       "\n",
       "    Elec.-ve  At.radii  Group  Work F.  Component_1  Component_2  Component_3  \\\n",
       "0       1.91       149   10.0     5.24    -1.915967    -0.943504    -0.132418   \n",
       "1       1.65       142   12.0     3.63    -3.982287    -2.807176    -1.550395   \n",
       "2       2.20       178    8.0     4.65     0.493640     1.231400    -0.433444   \n",
       "3       2.28       173    9.0     5.20    -0.143799     0.748347    -1.020538   \n",
       "4       2.20       169   10.0     5.47    -1.073746    -0.062325    -1.628189   \n",
       "..       ...       ...    ...      ...          ...          ...          ...   \n",
       "64      1.90       188    7.0     4.72     5.035730     1.600901    -0.101576   \n",
       "65      2.20       185    8.0     5.93     5.000112     1.739273    -0.376168   \n",
       "66      2.28       177   10.0     5.97     3.448784     0.669767    -1.917558   \n",
       "67      2.54       174   11.0     5.41     2.154261    -0.362528    -2.801696   \n",
       "68      2.02       143   15.0     4.34     0.420776    -2.170906    -3.034649   \n",
       "\n",
       "    Component_4  Component_5  Component_6  Component_7  \n",
       "0     -2.965627    -0.757080     1.676332    -0.241277  \n",
       "1     -1.175395    -1.854209     0.716056     2.623544  \n",
       "2     -3.414539     0.382485     1.612778     0.029696  \n",
       "3     -2.591706     0.318120     1.735927     0.103422  \n",
       "4     -1.860067    -0.483666     1.302271     1.168488  \n",
       "..          ...          ...          ...          ...  \n",
       "64    -1.242366     1.994269    -1.164954     0.754653  \n",
       "65    -1.336674    -0.145249    -1.331400    -0.041956  \n",
       "66     0.701586    -1.046711    -0.725332    -0.921569  \n",
       "67     1.947625    -1.679727    -0.625285    -0.861799  \n",
       "68     3.080016     0.233897    -0.522914     0.358786  \n",
       "\n",
       "[69 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba48fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4\n",
    "y = df2['OH_B.E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8183bc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 17), (21, 17))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9289beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on test data is 0.7792557184411745\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "print(\"r2 on test data is\",   r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85b6839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:0.25669672417323325\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\"+str(np.sqrt(mean_squared_error(y_test, y_predict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa493186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'grow_policy': 'depthwise',\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_bin': 256,\n",
       " 'max_cat_to_onehot': 4,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'max_leaves': 0,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 0,\n",
       " 'num_parallel_tree': 1,\n",
       " 'predictor': 'auto',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'sampling_method': 'uniform',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_params = model.get_params()\n",
    "H_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d44e8281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x221244b2790>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmnElEQVR4nO3deXyU5bn/8c9FCPu+QyAEZIegaAQVF1xBtAKirba1rkXb+mt72qOgqKUuFbW1x1ZbpS6VY6tWCIuIorihdQMUsrGFnbDvW0K26/dHxp6ICSTMmsn3/XrllZl5bua+5iF8efLMM9dt7o6IiMS/OtEuQEREIkOBLyJSSyjwRURqCQW+iEgtocAXEakl6ka7gGNp06aNp6SkRLsMEZEaY/HixTvdvW1F22I68FNSUli0aFG0yxARqTHMbH1l23RKR0SkllDgi4jUEgp8EZFaQoEvIlJLKPBFRGqJoAPfzLqY2ftmlmNm2Wb2iwrGmJn9ycxyzSzDzE4Ndl4REameUFyWWQz82t2/NLOmwGIze8fdc8qNuRToGfgaAvw18F1ERCIk6CN8d9/i7l8Gbh8AlgFJRw0bBUz1Mp8BLcysY7Bzi4jEm4XrdvP0h6vD8twhPYdvZinAIODzozYlARvL3d/Et/9T+Po5xpnZIjNbtGPHjlCWJyISsw4eKea+WVlc/fSn/PPzDRwuLA75HCH7pK2ZNQGmA7909/0n+jzuPgWYApCWlqbVWUQk7n24cgd3p2eyeV8+Nw5N4b8v6U2jeqFvhBCSZzSzRMrC/h/unl7BkDygS7n7nQOPiYjUWnsOFfLAGzmkf5lHj3ZNmHbbWZzWtWXY5gs68M3MgOeAZe7+eCXDZgO3m9krlL1Zu8/dtwQ7t4hITeTuvJm1lftmZbH3cBH/74Ie3H5BD+rXTQjrvKE4wh8KXAdkmtmSwGN3A8kA7v40MBcYCeQCh4EbQzCviEiNs31/AffOymJe9jZSk5oz9aYh9OvULCJzBx347v4xYMcZ48DPgp1LRKSmcndeW7yJB+fkcKS4lAmX9uGWs7tRNyFyn3+N6fbIIiLxYOPuw9yVnsnHuTsZnNKKyWNT6d62ScTrUOCLiIRJSanz4ifreGzeChLqGA+MHsAPBidTp84xT4qEjQJfRCQMVm07wPjpGXy5YS/Derfld2NS6dSiYVRrUuCLiIRQUUkpT3+wmj+/l0vj+gn8z/dOYdQpnSi7oDG6FPgiIiGSuWkfd0xbyvKtB7h8YEcmXdGfNk3qR7us/1Dgi4gEqaCohD/OX8nfFqyhTZP6TLnuNC7p3yHaZX2LAl9EJAifr9nFhPRM1u48xLWDuzDh0r40b5gY7bIqpMAXETkBBwqKeOSt5bz02QaSWzXin7cM4awebaJd1jEp8EVEqun95du5e0Ym2/YXcMvZ3fjVJb3C0uws1GK/QhGRGLH7UCH3v57NzCWb6dmuCX/5yVkMSg5fs7NQU+CLiByHuzMnYwuTZmezL7+IX1zYk5+ef1LYm52FmgJfROQYtu0vYOKMLOYv28bAzs35x4+H0KdDZJqdhZoCX0SkAu7Oqws38tDcZRSVlDJxZF9uHJoS0WZnoabAFxE5yvpdh7grPZNPVu/ijO6tmHzlQFLaNI52WUFT4IuIBJSUOi/8ey2/f3sFiXXq8LsxqVxzepeoNTsLNQW+iAiwYusB7pyewdKNe7mwTzseHDOAjs2j2+ws1EK1pu3zwOXAdncfUMH2YcAsYG3goXR3vz8Uc4uIBKOwuJS/fJDLU+/n0rRBIk9ccwpXnBwbzc5CLVRH+H8HngSmHmPMR+5+eYjmExEJ2tKNe7lzWgYrth1g1CmduO/yfrSOoWZnoRaSwHf3BWaWEornEhEJt/zCEh5/ZwXPfbyWdk0b8Nz1aVzYt320ywq7SJ7DP9PMlgKbgf929+yKBpnZOGAcQHJycgTLE5Ha4LG3lvP0gjWUlDr16tYhv7CYW15cRKcWDbljeG9GD0qKdolhE6nA/xLo6u4HzWwkMBPoWdFAd58CTAFIS0vzCNUnInFuf0ERt05dzKdrdv3nscLiUgqLSwHI25vPXemZAHEb+hH5BIG773f3g4Hbc4FEM4vttnIiEjfm52zj4sc//EbYVyS/qITH5q2IUFWRF5HAN7MOFnjL28wGB+Y99p4XEQnSroNH+PnLX3HL1EW0bFSvSn9m8978MFcVPaG6LPNlYBjQxsw2Ab8BEgHc/WngKuAnZlYM5APXuLtO14hIWLg7s5duZtLsbA4eKeZXF/fitvNO4vzff0DecQI92guNh1OortK59jjbn6Tssk0RkbDasi+fe2Zk8e7y7ZzSpQWPXjWQXu2bAnDH8N7clZ5JflFJhX+2YWICdwzvHclyI0qftBWRuFBa6ry8cAMPz11OSalz7+X9uOGsFBLKtUX4+s3Yx+atYPPefFo0SsQd9uUX6SodEZGaYO3OQ0yYnsHna3cztEdrHh4zkOTWjSocO3pQUlyH+rEo8EWkxiouKeX5f6/lD2+vpF7dOjwyNpXvpnWJy7YIoaDAF5EaadmW/YyfnkHGpn1c3K89D44eQPtmDaJdVkxT4ItIjXKkuISn3svlLx+spnnDRJ78/iAuS+2oo/oqUOCLSI3x5YY9jJ+WwartB7lyUBL3Xt6Plo2rdn29KPBFpAY4XFjM7+et5IVP1tKxWQNeuPF0zu/dLtpl1TgKfBGJaf/O3cmE9Aw27s7nujO6cueI3jRtkBjtsmokBb6IxKR9+UX87o1lvLpoI93aNObVcWcwpHvraJdVoynwRSTmvJ29lXtmZrHrUCG3nXcSv7yoJw0SE6JdVo2nwBeRmLHjwBEmvZ7NGxlb6NuxGc9dfzqpnZtHu6y4ocAXkahzd2Z8lcf9c3I4fKSEO4b3Zty53UlMiEhD31pDgS8iETXzqzwem7eCvL35JJhR4k79unU4UlzKqcllzc56tGsa7TLjkgJfRCJm5ld53+hWWRLokn6kuJTEOsYPh3RV2IeRfl8SkYh5bN6KSlsTF5U6f3hnZYQrql10hC8iIfP16ZrNe/MrbDd8vMVH4nm1qVgQqhWvngcuB7a7+4AKthvwBDASOAzc4O5fhmJuEYkNR5+u+XpR8EXrd/P+8h3HDXuI79WmYkGoTun8HRhxjO2XAj0DX+OAv4ZoXhGJERWdrskvKuGlzzZUKezjfbWpWBCSwHf3BcDuYwwZBUz1Mp8BLcysYyjmFpHYEMzpmKQWDXn4ytRauzBJpETqHH4SsLHc/U2Bx7YcPdDMxlH2WwDJyckRKU5EgtepRcMqHcmXZ8DayZeFpyD5lpi7Ssfdp7h7mruntW3bNtrliEgV3TG8Nw2r2f5A5+wjK1KBnwd0KXe/c+AxEYkTw3q3JTWp6m0QdM4+8iIV+LOBH1mZM4B97v6t0zkiUjO9mbmFix5fwOINe2hSv/IzxQmBVal0zj46QnVZ5svAMKCNmW0CfgMkArj708Bcyi7JzKXssswbQzGviETX9gMF/GZWNm9mbaV/p2a8eNPprNp28BuXZ0LZ0bwCPvpCEvjufu1xtjvws1DMJSLR5+5MW7yJB99YRn5RCXeO6M2Pzylrdta/U9lpnWN9AEuiQ5+0FZFq2bj7MHfPyOSjVTs5PaUlk8cO5KS2Tb4xZvSgJAV8DFLgi0iVlJY6Uz9dx6PzVmDA/aP688MhXalTx6JdmlSRAl9Ejit3+0EmTM9g0fo9nNerLQ+NGUDnlo2iXZZUkwJfRCpVVFLKlAVreGL+KhrVT+Dx757MmEFJmOmoviZS4ItIhbLy9nHntAxytuznstSOTLqiP22b1o92WRIEBb6IfENBUQlPvLuKKQvW0KpxPZ7+4WmMGNAh2mVJCCjwReQ/Fq7bzfhpGazZeYjvpnVm4sh+NG+UGO2yJEQU+CLCwSPFPPrWcqZ+up7OLRvy0s1DOLtnm2iXJSGmwBeJI8dbcaoi76/YzsT0TLbsL+Cmod349SW9aHyM9ghSc+lvVSROVLbiFFBh6O85VMgDc3JI/yqPHu2aMO22szita8uI1iyRpcAXiROVrTj12LwV3wh8d2du5lZ+MzuLvYeL+PkFPfjZBT2oX7d6rY2l5lHgi8SJylacKv/49v0F3DMzi7dztpGa1JypNw2hX6dmkSpRokyBLxInKltxqlOLhrg7ry3axANv5FBYXMpdl/bh5rO7UTch5tZAkjBS4IvUcF+/UZu3Nx8DvNw2A9JSWnLdc1/wce5OBndrxeQrU+l+VLMzqR0U+CJVdCJXwESipvJv1PpR2x2YtWQz9evW4cHRA2hUL4Hrnvsipl6DRE5Ifp8zsxFmtsLMcs1sQgXbbzCzHWa2JPB1SyjmFYmUr4M1b28+zv9dATPzq+iu1FnRG7UVadEokSb16zJxRlbMvQaJnKAD38wSgKeAS4F+wLVm1q+Coa+6+ymBr2eDnVckko51BUw4zfwqj6GT36PbhDcYOvm9b4VzZW/UHm37/iNRew0SO0JxSmcwkOvuawDM7BVgFJATgucWCZvqnKKpyhUw4ajveNfVV/ZG7dHqmFU6LpyvQWJLKE7pJAEby93fFHjsaGPNLMPMpplZl8qezMzGmdkiM1u0Y8eOEJQn8m3VPUXTqUXDaj0eClU5Ir9jeO8qPVeJH312//+E8zVIbInUNVmvAynuPhB4B3ixsoHuPsXd09w9rW3bthEqT2qb6p7euGN4bxomfvODSQ0TE6ocuCeiKr9VdGjegKYNTvwX9XC/BoktoQj8PKD8EXvnwGP/4e673P1I4O6zwGkhmFfkhFX3FM3oQUk8fGUqSS0aYkBSi4Y8fGVqWK9wOdZvFQcKipg4I5NrpnxGy0b1+Omwk0io5qIkkXgNEltCcQ5/IdDTzLpRFvTXAN8vP8DMOrr7lsDdK4BlIZhX5IQd60NKlYn0wtx3DO/9jXP4UHZEPjK1A5f8cQHb9hdwy9nd+PUlvWlYL4Fe7Zt+a/zR1+V/LalFQ/494YLwvwiJKUEf4bt7MXA7MI+yIP+Xu2eb2f1mdkVg2M/NLNvMlgI/B24Idl6RYETjFE11Hf1bRYdmDejXqRl/+2gtTRvUZfpPzuKey/vRsF5CheOTWjTkB2ckx/zrlMgxP8abOdGWlpbmixYtinYZEqdi8YNUFXF3Xs/YwqTZ2RwoKOKnw3rws/N7UK9u1Y7XasrrlNAws8XunlbhNgW+SOzauq+s2dn8Zds4uXNzHrlqIH06qNmZVO5Yga/WChK3avKRrbvzysKN/O6NZRSVlnLPZX25cWg3EupU741ZkfIU+BKXqrsYSCxZv+sQE6Zn8umaXZzZvTWTx6bStXXjaJclcUCBL3GpqouBxJKSUueFf6/l92+vILFOHR6+MpVrTu+CVfNyS5HKKPAlLkWjFUIwVmw9wJ3TM1i6cS8X9W3Hg6NT6dC8QbTLkjijwJe4dCLX2UdDYXEpT72fy18+yKVpg0T+dO0gvjOwo47qJSy03I3EpZpwnf2SjXu5/M8f8cS7qxiZ2pH5vzqPK07upLCXsNERvsSlr8/Tx+JVOvmFJfzh7RU8/++1tGvagOeuT+PCvu2jXZbUAgp8iVuRboVQFZ+s3smE6Zls2H2YHwxJZsKlfWjaIDHaZUktocAXiYD9BUU8PHcZL3+xkZTWjXhl3Bmc0b11tMuSWkaBLxJm83O2MXFmJjsOHOHWc7vzy4t6/af/jUgkKfBFwmTnwSP89vUcXl+6mT4dmvK3H6UxsHOLaJcltZgCXyTE3J1ZSzbz29ezOXikmF9d3Ivbzjupys3ORMJFgS8SQpv35nPPzCzeW76dQckteGTsQHq1bxrtskQABb5ISJSWOv/8YgOT31xOSalz3+X9uP6sFDU7k5iiwBcJ0tqdh5gwPYPP1+5maI/WPDxmIMmtG0W7LJFvCUngm9kI4AkgAXjW3Scftb0+MJWytWx3Ad9z93WhmFskWopLSnnu47U8/s5K6tWtw6NjB3J1Wmd9UlZiVtCBb2YJwFPAxcAmYKGZzXb3nHLDbgb2uHsPM7sGeAT4XrBzi0RLzub9jJ+eQWbePi7u154HRw+gfTM1O5PYFooj/MFArruvATCzV4BRQPnAHwVMCtyeBjxpZuaxvNyWSAWOFJfw5Hu5/PWD1bRolMhT3z+VkakddFQvNUIoAj8J2Fju/iZgSGVj3L3YzPYBrYGdRz+ZmY0DxgEkJyeHoDyR0Fi8fg/jp2eQu/0gV56axL2X9aNl43rRLkukymLuTVt3nwJMgbI1baNcjgiHC4t5bN4K/v7JOjo2a8ALN57O+b3bRbsskWoLReDnAV3K3e8ceKyiMZvMrC7QnLI3b6WWi/V1Zz9etZMJ6Rls2pPPj87syp0j+tCkfswdJ4lUSSh+chcCPc2sG2XBfg3w/aPGzAauBz4FrgLe0/l7ieV1Z/cdLuKhuTn8a9EmurVpzL9uPZPB3VpFtSaRYAUd+IFz8rcD8yi7LPN5d882s/uBRe4+G3gO+F8zywV2U/afgtRysbru7FtZW7l3Vha7DxXyk2En8YsLe9IgUc3OpOYLye+m7j4XmHvUY/eVu10AXB2KuSR+xNq6szsOHGHS7GzeyNxCv47NeOGG0xmQ1DwqtYiEg05GStTEyrqz7k76l3ncPyeH/MIS7hjem3HndicxQc3OJL7oJ1qiJhbWnc3bm88NLyzk168tpUe7Jsz9xTn87PweCnuJSzrCl6iJ5rqzpaXOS5+v55E3l+PApO/040dnplBHzc4kjinwJaqise7s6h0HmTA9g4Xr9nBOzzb8bkwqXVqp2ZnEPwW+1BpFJaX87aM1/M/8VTSoW4fHrhrIVadVv9lZrH92QKQyCnypFbLy9jF+egbZm/dz6YAO/HZUf9o1rX6zs1j+7IDI8SjwJa4VFJXw5/dW8fSHa2jZqB5//cGpXJra8YSfL1Y/OyBSFQp8iVuL1u3mzukZrNlxiKtO68w9l/WlRaPgmp3F2mcHRKpDgS9x59CRsmZnL366jk7NGzL1psGc26ttSJ47Vj47IHIidLGxxJUPV+7gkj8u4MVP13H9mSm8/V/nhizsITY+OyByonSEL3Fh7+FCHpizjOlfbuKkto157dYzSUsJfbOzaH52QCRYCnyp8d7M3MK9s7LZc7iQ28/vwe0X9Ahrs7NofHZAJBQU+FJjbd9fwH2zsnkreyv9OzXjxZtOp38nNTsTqYwCX2ocd2fa4k08MCeHguJSxo/ow4/P6UZd9b8ROSYFvtQoG3cf5u4ZmXy0aienp7Rk8tiBnNS2SbTLEqkRFPhSI5SUOlM/Xcdj81ZgwAOj+vODIV3V7EykGoIKfDNrBbwKpADrgO+6+54KxpUAmYG7G9z9imDmldold/sBxk/PZPH6PZzXqy2/uzKVJF33LlJtwR7hTwDedffJZjYhcH98BePy3f2UIOeSWqaopJRnPlzNn97NpVH9BB7/7smMGZRU7WZnIlIm2MAfBQwL3H4R+ICKA1+kWrLy9nHHtAyWbdnPZQM7Muk7/WnbtH60yxKp0YIN/PbuviVweyvQvpJxDcxsEVAMTHb3mZU9oZmNA8YBJCcnB1me1DQFRSX8z/xV/O2jNbRqXI9nrjuN4f07RLsskbhw3MA3s/lARf/iJpa/4+5uZl7J03R19zwz6w68Z2aZ7r66ooHuPgWYApCWllbZ80kc+nzNLiakZ7J25yG+l9aFu0f2pXmjxGiXJRI3jhv47n5RZdvMbJuZdXT3LWbWEdheyXPkBb6vMbMPgEFAhYEvtc+BgiIefWsF//vZejq3bMhLNw/h7J5tol2WSNwJ9pTObOB6YHLg+6yjB5hZS+Cwux8xszbAUODRIOeVOPH+iu1MTM9ky/4Cbhrajf8e3otG9XS1sEg4BPsvazLwLzO7GVgPfBfAzNKA29z9FqAv8IyZlVLWnXOyu+cEOa/UcHsOFfLAnBzSv8qjZ7smTP/JWZya3DLaZYnEtaAC3913ARdW8Pgi4JbA7U+A1GDmkfjh7ryRuYXfzMpmX34RP7+gBz+7oAf164av2ZmIlNHvzhIx2/YXcM/MLN7J2UZqUnNeumUIfTs2i3ZZIrWGAl/Czt3516KNPPjGMgqLS7nr0j7cfLaanYlEmgJfwmrDrsNMSM/gk9W7GNytFY+MHUi3No2jXZZIraTAl7AoKXX+/sk6fj9vBQl1jIfGDODa05PV7EwkihT4EnIrtx3gzmkZLNm4lwv6tOOhMQPo2FzNzkSiTYEvIVNYXMrTH67mz++tokn9ujxxzSlccXInNTsTiREKfAmJpRv3Mn56Bsu3HuA7J3di0nf60bqJmp2JxBIFvgQlv7CEP85fybMfraFt0/r87UdpXNyvsh56IhJNCnw5YZ+u3sVd6Rms23WYawcnc9fIPjRroGZnIrFKgS/Vtr+giMlvLuefn2+ga+tG/PPHQzjrJDU7E4l1CnyplveWb+Pu9Cy2Hyjgx+d041cX96ZhPbVFEKkJFPhSJbsOHuH+OTnMWrKZ3u2b8vR1p3FKlxbRLktEqkGBL8fk7sxeupnfvp7DgYIifnlRT346rAf16qotgkhNo8CXSm3Zl889M7J4d/l2Tu7SgkfHDqR3h6bRLktETpACX76ltNR5ZeFGHp67jKLSUu65rC83Du1GgtoiiNRoQf1ebmZXm1m2mZUGFj2pbNwIM1thZrlmNiGYOSW81u08xPef/Yy7Z2QyIKk58355Lrec011hLxIHgj3CzwKuBJ6pbICZJQBPARcDm4CFZjZbq17FlpJS5/mP1/KHd1aQWKcOk69M5Xund1FbBJE4EuyKV8uA44XCYCDX3dcExr4CjAIU+DFi+db9jJ+WwdJN+7iobzseHJ1Kh+YNol2WiIRYJM7hJwEby93fBAypbLCZjQPGASQnJ4e3slruSHEJT72/mr+8n0vzhon8+dpBXD6wo47qReLUcQPfzOYDHSrYNNHdZ4W6IHefAkwBSEtL81A/v5T5asMexk/PYOW2g4w+pRP3fac/rRrXi3ZZIhJGxw18d78oyDnygC7l7ncOPCZRcLiwmD+8vZLn/72WDs0a8PwNaVzQR83ORGqDSJzSWQj0NLNulAX9NcD3IzCvHOWT3J1MSM9kw+7D/PCMZMaP6ENTNTsTqTWCCnwzGwP8GWgLvGFmS9x9uJl1Ap5195HuXmxmtwPzgATgeXfPDrpyqbJ9+UU8PHcZryzcSErrRrwy7gzO6N462mWJSIQFe5XODGBGBY9vBkaWuz8XmBvMXHJi3s7eyj0zs9h58Ai3nted/7qoFw0S1exMpDbSJ23j1M6DR5g0O5s5GVvo06Epz16fxsDOLaJdlohEkQI/zrg7M5fk8dvXczh8pIRfX9yLW887Sc3ORESBH082781n4oxM3l+xg0HJZc3OerZXszMRKaPAjwOlpc4/vtjAI28up6TUue/yflx/Vor634jINyjwa7g1Ow4yIT2TL9bu5uwebXj4ylS6tGoU7bJEJAYp8Guo4pJSnv14LX98ZyX16tbh0bEDuTqts9oiiEilFPg1UM7m/dw5fSlZefu5pF97Hhg9gPbN1OxMRI5NgV+DHCku4cn3cvnrB6tp0SiRv/zgVC4d0EFH9SJSJQr8GmLx+rJmZ7nbD3LlqUnce1k/WqrZmYhUgwI/xh06Uszv317B3z9ZR6fmDfn7jaczrHe7aJclIjWQAj+GfbRqB3elZ7JpTz4/OrMrd47oQ5P6+isTkROj9IhB+w4X8eAbOby2eBPd2zTmX7eeyeBuraJdlojUcAr8GPNW1lbunZXF7kOF/GTYSfziwp5qdiYiIaHAjxHbDxQwaXY2czO30q9jM1644XQGJDWPdlkiEkcU+FHm7qR/mcf9c3LILyrhjuG9GXdudxIT1OxMREJLgR9Fm/Yc5u4ZWSxYuYPTurbkkbED6dGuSbTLEpE4FeyKV1cDk4C+wGB3X1TJuHXAAaAEKHb3tGDmrelKS53//Ww9j7y1HIDfXtGf687oSh01OxORMAr2CD8LuBJ4pgpjz3f3nUHOV+Ot3nGQ8dMyWLR+D+f0bMPvxqjZmYhERrBLHC4D9NH+KigqKWXKgjU88e4qGiYm8PurT2bsqUnadyISMZE6h+/A22bmwDPuPqWygWY2DhgHkJycHKHywisrbx/jp2eQvXk/I1M7MOmK/rRrqmZnIhJZxw18M5sPdKhg00R3n1XFec529zwzawe8Y2bL3X1BRQMD/xlMAUhLS/MqPn9MKigq4U/vruKZBWto2ageT//wVEYM6BjtskSkljpu4Lv7RcFO4u55ge/bzWwGMBioMPDjxcJ1uxk/PYM1Ow5x9WmdueeyfjRvlBjtskSkFgv7KR0zawzUcfcDgduXAPeHe95oOXikmEffWs7UT9eT1KIhU28azLm92ka7LBGRoC/LHAP8GWgLvGFmS9x9uJl1Ap5195FAe2BG4M3JusA/3f2tIOuOSR+u3MHd6Zls3pfPDWelcMfw3jRWszMRiRHBXqUzA5hRweObgZGB22uAk4OZJ9btPVzI/XNySP8yj5PaNua1W88kLUXNzkQktujwM0hzM7dw36ws9h4u4vbze3D7BT3U7ExEYpIC/wRt31/AvbOymJe9jQFJzXjxpsH076RmZyISuxT41eTuvLZ4Ew/OyaGguJTxI/rw43O6UVfNzkQkxinwq2Hj7sPclZ7Jx7k7GZzSisljU+neVs3ORKRmUOBXQUmpM/XTdTz61grqGDwwqj8/GKJmZyJSsyjwjyN3+wHunJbBlxv2Mqx3Wx4ak0pSi4bRLktEpNoU+JUoKinlmQ9X86d3c2lUP4E/fu9kRp+iZmciUnMp8CuQuWkfd0xbyvKtB7hsYEd+e0V/2jSpH+2yRESCosAvp6CohD/OX8nfFqyhTZP6PHPdaQzvX1HfOBGRmkeBH/D5ml1MSM9k7c5DfC+tC3df1pfmDdXsTETiR60P/AMFRTzy1nJe+mwDXVo15B+3DGFojzbRLktEJORqdeC/v3w7E2dksmV/ATef3Y1fX9KLRvVq9S4RkThWK9Nt96FCHpiTw4yv8ujZrgnTf3IWpya3jHZZIiJhVasC392Zk7GFSbOz2ZdfxM8v7MnPzj+J+nXV7ExE4l+tCfxt+wuYOCOL+cu2MbBzc166ZQh9OzaLdlkiIhET94Hv7ry6cCMPzV1GYXEpd4/sw01D1exMRGqfYFe8egz4DlAIrAZudPe9FYwbATwBJFC2EtbkYOatqg27DjMhPYNPVu9iSLdWPDJ2ICltGkdiahGRmBPsYe47wAB3HwisBO46eoCZJQBPAZcC/YBrzaxfkPMeU0mp8+xHa7jkfz4kY9M+HhozgJd/fIbCXkRqtWCXOHy73N3PgKsqGDYYyA0sdYiZvQKMAnKCmbsy+w4Xcf0LX7Bk414u6NOOh8YMoGNzNTsTEQnlOfybgFcreDwJ2Fju/iZgSGVPYmbjgHEAycnJ1S6iWcO6dG3diBuHpnDFyZ3U7ExEJOC4gW9m84GKGspMdPdZgTETgWLgH8EW5O5TgCkAaWlpXt0/b2Y8cc2gYMsQEYk7xw18d7/oWNvN7AbgcuBCd68ooPOALuXudw48JiIiERTUm7aBq2/uBK5w98OVDFsI9DSzbmZWD7gGmB3MvCIiUn3BXqXzJNAUeMfMlpjZ0wBm1snM5gK4ezFwOzAPWAb8y92zg5xXRESqKdirdHpU8vhmYGS5+3OBucHMJSIiwdHHTUVEagkFvohILaHAFxGpJRT4IiK1hFV86XxsMLMdwPoT/ONtgJ0hLCdUVFf1qK7qUV3VE491dXX3thVtiOnAD4aZLXL3tGjXcTTVVT2qq3pUV/XUtrp0SkdEpJZQ4IuI1BLxHPhTol1AJVRX9aiu6lFd1VOr6orbc/giIvJN8XyELyIi5SjwRURqibgJfDN7zMyWm1mGmc0wsxaVjBthZivMLNfMJkSgrqvNLNvMSs2s0suszGydmWUGuo4uiqG6Ir2/WpnZO2a2KvC9ZSXjSgL7aomZha3d9vFev5nVN7NXA9s/N7OUcNVSzbpuMLMd5fbRLRGo6Xkz225mWZVsNzP7U6DmDDM7Ndw1VbGuYWa2r9y+ui9CdXUxs/fNLCfwb/EXFYwJ7T5z97j4Ai4B6gZuPwI8UsGYBGA10B2oBywF+oW5rr5Ab+ADIO0Y49YBbSK4v45bV5T216PAhMDtCRX9PQa2HYzAPjru6wd+CjwduH0N8GqM1HUD8GSkfp4Cc54LnApkVbJ9JPAmYMAZwOcxUtcwYE4k91Vg3o7AqYHbTYGVFfw9hnSfxc0Rvru/7WW996FsQfXOFQz7z4Lq7l4IfL2gejjrWubuK8I5x4moYl0R31+B538xcPtFYHSY5zuWqrz+8vVOAy608C+kHI2/l+Ny9wXA7mMMGQVM9TKfAS3MrGMM1BUV7r7F3b8M3D5A2XohSUcNC+k+i5vAP8pNlP2veLSKFlQ/egdHiwNvm9niwELusSAa+6u9u28J3N4KtK9kXAMzW2Rmn5nZ6DDVUpXX/58xgQOOfUDrMNVTnboAxgZOA0wzsy4VbI+0WP73d6aZLTWzN82sf6QnD5wKHAR8ftSmkO6zoBZAibRIL6geyrqq4Gx3zzOzdpStILY8cGQS7bpC7lh1lb/j7m5mlV033DWwv7oD75lZpruvDnWtNdjrwMvufsTMbqXst5ALolxTrPqSsp+ng2Y2EpgJ9IzU5GbWBJgO/NLd94dzrhoV+B6jC6ofr64qPkde4Pt2M5tB2a/tQQV+COqK+P4ys21m1tHdtwR+dd1eyXN8vb/WmNkHlB0dhTrwq/L6vx6zyczqAs2BXSGuo9p1uXv5Gp6l7L2RaAvLz1Owyoesu881s7+YWRt3D3tTNTNLpCzs/+Hu6RUMCek+i5tTOlaDF1Q3s8Zm1vTr25S9AV3hFQURFo39NRu4PnD7euBbv4mYWUszqx+43QYYCuSEoZaqvP7y9V4FvFfJwUZE6zrqPO8VlJ0fjrbZwI8CV56cAewrd/ouasysw9fvu5jZYMpyMdz/aROY8zlgmbs/Xsmw0O6zSL8zHa4vIJeyc11LAl9fXznRCZhbbtxIyt4NX03ZqY1w1zWGsvNuR4BtwLyj66Lsaoulga/sWKkrSvurNfAusAqYD7QKPJ4GPBu4fRaQGdhfmcDNYaznW68fuJ+yAwuABsBrgZ+/L4Du4d5HVazr4cDP0lLgfaBPBGp6GdgCFAV+tm4GbgNuC2w34KlAzZkc46q1CNd1e7l99RlwVoTqOpuy9+4yyuXWyHDuM7VWEBGpJeLmlI6IiBybAl9EpJZQ4IuI1BIKfBGRWkKBLyJSSyjwRURqCQW+iEgt8f8BCIw+GpHg2dsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_predict)\n",
    "plt.plot([-2,2], [-2,2],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "476ea20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv('Cu_based_bi_OH_BE.csv')\n",
    "df_pred\n",
    "selected_columns = df_pred[[\"Element\"]]\n",
    "new_df = selected_columns.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeec5090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>...</th>\n",
       "      <th>Sp.ht Cap</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.20</td>\n",
       "      <td>633.10</td>\n",
       "      <td>170</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.500</td>\n",
       "      <td>18.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.93</td>\n",
       "      <td>658.80</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.330</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>489.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.38</td>\n",
       "      <td>650.90</td>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4.300</td>\n",
       "      <td>50.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.22</td>\n",
       "      <td>652.90</td>\n",
       "      <td>139</td>\n",
       "      <td>166</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.500</td>\n",
       "      <td>64.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.39</td>\n",
       "      <td>717.30</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.100</td>\n",
       "      <td>-50.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.11</td>\n",
       "      <td>760.40</td>\n",
       "      <td>126</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000</td>\n",
       "      <td>63.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>445.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>737.10</td>\n",
       "      <td>121</td>\n",
       "      <td>149</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5.240</td>\n",
       "      <td>112.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>388.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.33</td>\n",
       "      <td>906.40</td>\n",
       "      <td>122</td>\n",
       "      <td>142</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3.630</td>\n",
       "      <td>-58.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.48</td>\n",
       "      <td>578.80</td>\n",
       "      <td>122</td>\n",
       "      <td>136</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4.320</td>\n",
       "      <td>28.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>600.00</td>\n",
       "      <td>190</td>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.183</td>\n",
       "      <td>29.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.60</td>\n",
       "      <td>640.10</td>\n",
       "      <td>175</td>\n",
       "      <td>206</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.050</td>\n",
       "      <td>41.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.06</td>\n",
       "      <td>652.10</td>\n",
       "      <td>164</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.360</td>\n",
       "      <td>86.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>251.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.78</td>\n",
       "      <td>684.30</td>\n",
       "      <td>154</td>\n",
       "      <td>190</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4.520</td>\n",
       "      <td>71.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>710.20</td>\n",
       "      <td>126</td>\n",
       "      <td>178</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4.650</td>\n",
       "      <td>101.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.98</td>\n",
       "      <td>719.70</td>\n",
       "      <td>135</td>\n",
       "      <td>173</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5.200</td>\n",
       "      <td>109.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>804.40</td>\n",
       "      <td>131</td>\n",
       "      <td>169</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.470</td>\n",
       "      <td>53.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>731.00</td>\n",
       "      <td>145</td>\n",
       "      <td>165</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4.630</td>\n",
       "      <td>125.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.54</td>\n",
       "      <td>708.60</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>4.420</td>\n",
       "      <td>107.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.34</td>\n",
       "      <td>761.00</td>\n",
       "      <td>170</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>31.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.57</td>\n",
       "      <td>760.00</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4.720</td>\n",
       "      <td>14.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.00</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5.930</td>\n",
       "      <td>106.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>137</td>\n",
       "      <td>180</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5.760</td>\n",
       "      <td>151.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.00</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5.970</td>\n",
       "      <td>205.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>136</td>\n",
       "      <td>174</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5.410</td>\n",
       "      <td>222.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>904.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>577.50</td>\n",
       "      <td>121</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>4.040</td>\n",
       "      <td>42.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>710.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.30</td>\n",
       "      <td>786.50</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4.637</td>\n",
       "      <td>134.068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    M-At No.  M-At wt.  M-Density  M-M.P  M-B.P  M-Enth.fus  M-Enth.atom  \\\n",
       "0         29    63.546       8.96   1357   2835        13.1          338   \n",
       "1         29    63.546       8.96   1357   2835        13.1          338   \n",
       "2         29    63.546       8.96   1357   2835        13.1          338   \n",
       "3         29    63.546       8.96   1357   2835        13.1          338   \n",
       "4         29    63.546       8.96   1357   2835        13.1          338   \n",
       "5         29    63.546       8.96   1357   2835        13.1          338   \n",
       "6         29    63.546       8.96   1357   2835        13.1          338   \n",
       "7         29    63.546       8.96   1357   2835        13.1          338   \n",
       "8         29    63.546       8.96   1357   2835        13.1          338   \n",
       "9         29    63.546       8.96   1357   2835        13.1          338   \n",
       "10        29    63.546       8.96   1357   2835        13.1          338   \n",
       "11        29    63.546       8.96   1357   2835        13.1          338   \n",
       "12        29    63.546       8.96   1357   2835        13.1          338   \n",
       "13        29    63.546       8.96   1357   2835        13.1          338   \n",
       "14        29    63.546       8.96   1357   2835        13.1          338   \n",
       "15        29    63.546       8.96   1357   2835        13.1          338   \n",
       "16        29    63.546       8.96   1357   2835        13.1          338   \n",
       "17        29    63.546       8.96   1357   2835        13.1          338   \n",
       "18        29    63.546       8.96   1357   2835        13.1          338   \n",
       "19        29    63.546       8.96   1357   2835        13.1          338   \n",
       "20        29    63.546       8.96   1357   2835        13.1          338   \n",
       "21        29    63.546       8.96   1357   2835        13.1          338   \n",
       "22        29    63.546       8.96   1357   2835        13.1          338   \n",
       "23        29    63.546       8.96   1357   2835        13.1          338   \n",
       "24        29    63.546       8.96   1357   2835        13.1          338   \n",
       "25        29    63.546       8.96   1357   2835        13.1          338   \n",
       "\n",
       "    M-Enth.vap  M-Sp.ht Cap  M-Elec.-ve  ...  Sp.ht Cap  Elec.-ve  Surface.E  \\\n",
       "0          300        384.4         1.9  ...      567.0      1.36       1.20   \n",
       "1          300        384.4         1.9  ...      520.0      1.54       1.93   \n",
       "2          300        384.4         1.9  ...      489.0      1.63       2.38   \n",
       "3          300        384.4         1.9  ...      448.0      1.66       3.22   \n",
       "4          300        384.4         1.9  ...      479.0      1.55       3.39   \n",
       "5          300        384.4         1.9  ...      421.0      1.88       2.11   \n",
       "6          300        384.4         1.9  ...      445.0      1.91       1.92   \n",
       "7          300        384.4         1.9  ...      388.0      1.65       0.33   \n",
       "8          300        384.4         1.9  ...      371.0      1.81       0.48   \n",
       "9          300        384.4         1.9  ...      298.0      1.22       1.00   \n",
       "10         300        384.4         1.9  ...      278.0      1.33       1.60   \n",
       "11         300        384.4         1.9  ...      265.0      1.60       2.06   \n",
       "12         300        384.4         1.9  ...      251.0      2.16       2.78   \n",
       "13         300        384.4         1.9  ...      238.0      2.20       2.60   \n",
       "14         300        384.4         1.9  ...      240.0      2.28       1.98   \n",
       "15         300        384.4         1.9  ...      240.0      2.20       1.36   \n",
       "16         300        384.4         1.9  ...      235.0      1.93       0.76   \n",
       "17         300        384.4         1.9  ...      217.0      1.96       0.54   \n",
       "18         300        384.4         1.9  ...      140.0      1.50       2.34   \n",
       "19         300        384.4         1.9  ...      137.0      1.90       2.57   \n",
       "20         300        384.4         1.9  ...      130.0      2.20       2.95   \n",
       "21         300        384.4         1.9  ...      131.0      2.20       2.36   \n",
       "22         300        384.4         1.9  ...      133.0      2.28       1.49   \n",
       "23         300        384.4         1.9  ...      129.1      2.54       0.74   \n",
       "24         300        384.4         1.9  ...      904.0      1.61       0.80   \n",
       "25         300        384.4         1.9  ...      710.0      1.90       1.30   \n",
       "\n",
       "    1st Ion E  cova .radii  At.radii  Group  Period  Work F.  Elec.Aff  \n",
       "0      633.10          170       184      3       4    3.500    18.100  \n",
       "1      658.80          160       176      4       4    4.330     7.600  \n",
       "2      650.90          153       171      5       4    4.300    50.600  \n",
       "3      652.90          139       166      6       4    4.500    64.300  \n",
       "4      717.30          139       161      7       4    4.100   -50.000  \n",
       "5      760.40          126       152      9       4    5.000    63.700  \n",
       "6      737.10          121       149     10       4    5.240   112.000  \n",
       "7      906.40          122       142     12       4    3.630   -58.000  \n",
       "8      578.80          122       136     13       4    4.320    28.900  \n",
       "9      600.00          190       212      3       5    3.183    29.600  \n",
       "10     640.10          175       206      4       5    4.050    41.100  \n",
       "11     652.10          164       198      5       5    4.360    86.100  \n",
       "12     684.30          154       190      6       5    4.520    71.900  \n",
       "13     710.20          126       178      8       5    4.650   101.300  \n",
       "14     719.70          135       173      9       5    5.200   109.700  \n",
       "15     804.40          131       169     10       5    5.470    53.700  \n",
       "16     731.00          145       165     11       5    4.630   125.600  \n",
       "17     708.60          139       145     14       5    4.420   107.300  \n",
       "18     761.00          170       200      5       6    4.000    31.000  \n",
       "19     760.00          159       188      7       6    4.720    14.500  \n",
       "20     840.00          128       185      8       6    5.930   106.100  \n",
       "21     880.00          137       180      9       6    5.760   151.000  \n",
       "22     870.00          136       177     10       6    5.970   205.300  \n",
       "23     890.13          136       174     11       6    5.410   222.800  \n",
       "24     577.50          121       118     13       3    4.040    42.500  \n",
       "25     786.50          111       111     14       3    4.637   134.068  \n",
       "\n",
       "[26 rows x 36 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_pred.drop(labels=[\"Element\",\"OH_B.E\"], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18513ca5",
   "metadata": {},
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc8a75",
   "metadata": {},
   "source": [
    "p = model.predict(x)\n",
    "p = pd.DataFrame(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7405770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0000234e-02 1.7481649e-01 1.3001833e-05 5.0166988e-01 1.3555029e-01\n",
      " 3.6047077e-06 6.0097199e-02 6.7030410e-03 1.3119780e-02 1.4295859e-03\n",
      " 4.3186088e-04 8.1814511e-04 4.7987126e-04 9.4587933e-03 6.6121953e-04\n",
      " 5.4464187e-02 2.8287226e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab02332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.stats.qmc import Sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85fed8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "params = { 'max_depth': np.arange(8,12,1),                      #10\n",
    "           'learning_rate': np.arange(0.01,0.2, 0.01),         #0.071\n",
    "           'subsample': np.arange(0.7, 1.0, 0.01),              #0.75\n",
    "           #'colsample_bytree': np.arange(0.9, 1, 0.02),         #0.82\n",
    "           'min_child_weight': np.arange(5,15, 1),\n",
    "           #'colsample_bylevel': np.arange(0.9, 1, 0.02),        #0.72\n",
    "           'n_estimators': np.arange(400,1000,25),                #116\n",
    "           #'reg_alpha': uniform(0.1,5),                     #0.8612124738904751\n",
    "           #'reg_lambda': uniform(0.1,5),                      #115.01455430429743  \n",
    "         }\n",
    "sobol_sequence = Sobol(1)\n",
    "lasso = Lasso()\n",
    "# number of times random search is run\n",
    "n = 50                                       # n=20    #n_iter=50  #cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc630665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 1: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.16, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=675, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 1th run - Training: 0.0005104055600070949, Test: 0.20203112528490488\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 2: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.15000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=400, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 2th run - Training: 0.0010930829048585052, Test: 0.19629167213514367\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 3: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.19, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=750, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 3th run - Training: 0.0006143228584009264, Test: 0.20471860475589815\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 4: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.14, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=600, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 4th run - Training: 0.0005475380531641985, Test: 0.21241745087089162\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 5: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.15000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=8, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=700, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 5th run - Training: 0.000489139616701339, Test: 0.20897716895171173\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 6: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.05, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=450, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 6th run - Training: 0.0171040255713061, Test: 0.18663968584870066\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 7: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.05, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=500, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 7th run - Training: 0.013704408830640516, Test: 0.1856353229732015\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 8: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=10, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=675, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 8th run - Training: 0.0006067982593846911, Test: 0.19383244018273885\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 9: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.13, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=675, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 9th run - Training: 0.0005877383665780408, Test: 0.18592223688766543\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 10: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=750, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 10th run - Training: 0.0006695284992004886, Test: 0.21469289706870043\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 11: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.13, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=725, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 11th run - Training: 0.00047867951116732817, Test: 0.1904261056771236\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 12: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=600, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 12th run - Training: 0.0007926155667462488, Test: 0.21693812377000868\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 13: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.06999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=650, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 13th run - Training: 0.0014654941322540841, Test: 0.19214495940601803\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 14: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.15000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=550, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 14th run - Training: 0.0005001178443180511, Test: 0.22605259642599598\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 15: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.12, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=700, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 15th run - Training: 0.0005230616392285468, Test: 0.1794164968077553\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 16: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=500, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 16th run - Training: 0.003847955988153469, Test: 0.20369327848415658\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 17: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.13, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=525, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 17th run - Training: 0.0006224704550134264, Test: 0.20998484032725165\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 18: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.18000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=10, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=400, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 18th run - Training: 0.0006993834139157357, Test: 0.20899489424783402\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 19: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.14, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=700, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 19th run - Training: 0.000551578603179397, Test: 0.19489473479747502\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 20: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.14, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=400, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 20th run - Training: 0.0008298048448807524, Test: 0.21220242122629496\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 21: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.060000000000000005, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=775, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 21th run - Training: 0.002965718981992815, Test: 0.19341371746765448\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 22: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.16, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=725, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 22th run - Training: 0.0005261675160675492, Test: 0.19780913834598177\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 23: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=11, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=425, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 23th run - Training: 0.0016137205035467962, Test: 0.2049104072310769\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 24: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.16, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=500, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 24th run - Training: 0.0005027345733604296, Test: 0.235677454795529\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 25: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.13, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=550, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 25th run - Training: 0.0005085833515841951, Test: 0.18207905111173528\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 26: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=625, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 26th run - Training: 0.0012509595956101348, Test: 0.2038879736284049\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 27: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.13, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=750, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 27th run - Training: 0.0004949425221164471, Test: 0.18207821340412367\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 28: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.13, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=725, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 28th run - Training: 0.0005208405194905002, Test: 0.21003849358303386\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 29: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.16, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=475, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 29th run - Training: 0.0006627991538424027, Test: 0.2209035177280064\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 30: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.06999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=8, max_leaves=0,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=775, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 30th run - Training: 0.0006817779022728378, Test: 0.1812240939636269\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 31: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.08, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=675, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 31th run - Training: 0.0015568740861770967, Test: 0.21567475996046592\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 32: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.08, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=450, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 32th run - Training: 0.0047619289765559614, Test: 0.19450457118968678\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 33: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.15000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=11, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=450, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 33th run - Training: 0.0006160412653416467, Test: 0.19710298583550412\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 34: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=450, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 34th run - Training: 0.0037559817681890994, Test: 0.2077932970559497\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 35: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.12, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=625, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 35th run - Training: 0.0005352480199644849, Test: 0.18500360211462039\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 36: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.08, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=775, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 36th run - Training: 0.0010907210114082793, Test: 0.19861907733284925\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 37: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.06999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=750, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 37th run - Training: 0.001419102428156618, Test: 0.19315166050668414\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 38: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.12, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=725, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 38th run - Training: 0.0005542060138738306, Test: 0.1778803051775304\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 39: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.08, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=525, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 39th run - Training: 0.004303094446137929, Test: 0.211931112810389\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 40: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.18000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=10, max_leaves=0,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=425, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 40th run - Training: 0.0005841624432514013, Test: 0.20735113834968358\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 41: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.06999999999999999, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=8, max_leaves=0,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=400, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 41th run - Training: 0.007273216503223696, Test: 0.18187671018351767\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 42: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.14, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=600, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 42th run - Training: 0.00052120939783849, Test: 0.1731420499665705\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 43: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.14, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=625, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 43th run - Training: 0.0005525341573092531, Test: 0.19928266982255421\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 44: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.09, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=550, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 44th run - Training: 0.002516769685395359, Test: 0.20397858471293287\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 45: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.18000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=9, max_leaves=0,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=750, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 45th run - Training: 0.0004238698282987489, Test: 0.23884668577657814\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 46: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.13, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=425, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 46th run - Training: 0.0006010234334000787, Test: 0.17588205406010274\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 47: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.18000000000000002, max_bin=256,\n",
      "             max_cat_to_onehot=4, max_delta_step=0, max_depth=10, max_leaves=0,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=550, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "             random_state=20, reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 47th run - Training: 0.0004739482910909579, Test: 0.2413373771422086\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 48: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.14, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=575, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 48th run - Training: 0.0005125681988728965, Test: 0.2183305127497375\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 49: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.11, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=5,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=525, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 49th run - Training: 0.0011337851546506254, Test: 0.22212428747879953\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 50: Best Estimator: XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.16, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=9, max_leaves=0, min_child_weight=6,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=575, n_jobs=0,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=20,\n",
      "             reg_alpha=0, reg_lambda=1, ...)\n",
      "RMSE for every 50th run - Training: 0.0006148681629154776, Test: 0.20281864319179072\n"
     ]
    }
   ],
   "source": [
    "xgbr = xgb.XGBRegressor(seed=20)\n",
    "average = np.array([0]*17, dtype=np.float64)\n",
    "feature_importances = []\n",
    "\n",
    "nth_run = 1\n",
    "rmse_values_test = []\n",
    "rmse_values_train = []\n",
    "avg = 0\n",
    "\n",
    "for i in range(n):   \n",
    "    clf = RandomizedSearchCV(estimator=xgbr,\n",
    "                             param_distributions=params,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             n_iter=30,cv=10,random_state=np.random.RandomState(int(sobol_sequence.random(1)[0] * 2**31)),\n",
    "                             verbose=1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    print(f\"Run {i + 1}: Best Estimator: {clf.best_estimator_}\")\n",
    "    \n",
    "    if (i + 1) % nth_run == 0:\n",
    "        # Predictions on test set\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        rmse_values_test.append(rmse_test)\n",
    "        \n",
    "        # Predictions on training set\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        rmse_values_train.append(rmse_train)\n",
    "\n",
    "        print(f\"RMSE for every {nth_run}th run - Training: {rmse_train}, Test: {rmse_test}\")\n",
    "        nth_run += 1\n",
    "    \n",
    "    average += clf.best_estimator_.feature_importances_\n",
    "    feature_importances.append(clf.best_estimator_.feature_importances_)\n",
    "average = average/n\n",
    "avg = avg/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6969f9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.4660915e-02, 8.7131418e-02, 1.7159164e-01, 4.5828488e-01,\n",
       "        1.0031839e-01, 2.3872971e-04, 2.4940573e-02, 1.6499333e-02,\n",
       "        6.2358923e-02, 1.1177232e-02, 2.5997751e-03, 1.2715005e-03,\n",
       "        1.2611666e-03, 2.7610397e-02, 1.3596690e-03, 1.9438263e-03,\n",
       "        6.7516332e-03], dtype=float32),\n",
       " array([2.22590808e-02, 7.46611804e-02, 5.43383248e-02, 5.36661327e-01,\n",
       "        1.60781413e-01, 1.04651976e-04, 3.05337850e-02, 1.61502846e-02,\n",
       "        4.46054749e-02, 1.52231371e-02, 2.26818956e-03, 9.98052652e-04,\n",
       "        1.18582952e-03, 2.87281927e-02, 1.85666140e-03, 5.99957304e-03,\n",
       "        3.64478258e-03], dtype=float32),\n",
       " array([2.3612965e-02, 1.3527277e-01, 9.7765951e-07, 5.7626700e-01,\n",
       "        9.4196118e-02, 1.1297336e-04, 1.9753451e-02, 8.0031510e-03,\n",
       "        1.1719319e-01, 8.1090080e-03, 6.0520915e-04, 5.4558978e-04,\n",
       "        2.9194346e-04, 6.9715190e-03, 1.1084512e-03, 1.4979577e-03,\n",
       "        6.4577558e-03], dtype=float32),\n",
       " array([0.02618761, 0.07903759, 0.16357489, 0.4038232 , 0.16788068,\n",
       "        0.00100246, 0.02917507, 0.01853306, 0.06903672, 0.00530738,\n",
       "        0.00194731, 0.00124747, 0.00122606, 0.0249684 , 0.00102181,\n",
       "        0.0005106 , 0.00551964], dtype=float32),\n",
       " array([1.7276540e-02, 7.6752469e-02, 6.3460641e-02, 4.9083751e-01,\n",
       "        2.0058832e-01, 2.3362425e-04, 3.1254727e-02, 1.3623467e-02,\n",
       "        5.3289004e-02, 9.4986204e-03, 2.1292346e-03, 1.4586465e-03,\n",
       "        1.2365186e-03, 2.6780672e-02, 2.9977995e-03, 5.9490940e-03,\n",
       "        2.6331288e-03], dtype=float32),\n",
       " array([0.02250012, 0.0419559 , 0.06239761, 0.4866939 , 0.20881367,\n",
       "        0.00050032, 0.02038964, 0.01791192, 0.09383743, 0.00632762,\n",
       "        0.00234268, 0.0015263 , 0.00200063, 0.02292394, 0.00356727,\n",
       "        0.00382185, 0.00248918], dtype=float32),\n",
       " array([2.0778395e-02, 4.3706305e-02, 6.5000847e-02, 4.8587909e-01,\n",
       "        2.1752541e-01, 4.4427850e-04, 2.0072859e-02, 1.6396139e-02,\n",
       "        8.8753030e-02, 5.8780443e-03, 2.0954199e-03, 1.4576789e-03,\n",
       "        1.8693319e-03, 2.0862592e-02, 3.4253136e-03, 3.5201169e-03,\n",
       "        2.3351007e-03], dtype=float32),\n",
       " array([2.4194824e-02, 6.1604828e-02, 2.2562385e-01, 3.9406759e-01,\n",
       "        1.5280093e-01, 8.0136859e-05, 2.3715414e-02, 2.7001562e-02,\n",
       "        5.7507891e-02, 3.5386665e-03, 1.3295227e-03, 1.0770769e-03,\n",
       "        7.0598727e-04, 1.8197127e-02, 1.9654045e-03, 2.8828895e-03,\n",
       "        3.7063833e-03], dtype=float32),\n",
       " array([2.7127942e-02, 5.3105082e-02, 1.5704334e-02, 7.0321691e-01,\n",
       "        9.9984735e-02, 3.8533891e-04, 5.6394715e-02, 1.8858006e-03,\n",
       "        1.4780566e-02, 1.1132346e-02, 5.7224656e-04, 2.9073158e-04,\n",
       "        5.8268994e-04, 9.3166409e-03, 7.9719292e-04, 4.5185853e-04,\n",
       "        4.2708996e-03], dtype=float32),\n",
       " array([0.03056943, 0.07225771, 0.07208314, 0.4516288 , 0.1355606 ,\n",
       "        0.0430872 , 0.05619914, 0.01496243, 0.07008447, 0.00815052,\n",
       "        0.00230676, 0.00335505, 0.00140984, 0.03358228, 0.00144641,\n",
       "        0.00199818, 0.00131801], dtype=float32),\n",
       " array([2.4580998e-02, 5.7497516e-02, 1.1624961e-01, 4.8348671e-01,\n",
       "        1.7347214e-01, 3.8616554e-04, 4.1947395e-02, 8.6845290e-03,\n",
       "        4.0781807e-02, 1.3164551e-02, 7.3420338e-04, 1.0765847e-03,\n",
       "        8.6006353e-04, 3.1120315e-02, 1.6131009e-03, 7.0572848e-04,\n",
       "        3.6385327e-03], dtype=float32),\n",
       " array([0.0271701 , 0.0886262 , 0.05084864, 0.43460476, 0.18096589,\n",
       "        0.03856067, 0.05699999, 0.02054234, 0.04410215, 0.007152  ,\n",
       "        0.00230439, 0.00318877, 0.00077704, 0.03442613, 0.00197527,\n",
       "        0.00607555, 0.00168012], dtype=float32),\n",
       " array([2.5756864e-02, 6.1052244e-02, 8.3309665e-02, 4.1953784e-01,\n",
       "        2.4078080e-01, 3.9062131e-04, 6.2913358e-02, 9.3336683e-03,\n",
       "        5.1536687e-02, 1.1401191e-02, 1.4762044e-03, 8.5539662e-04,\n",
       "        1.0574830e-03, 2.5926290e-02, 9.6684252e-04, 6.7820126e-04,\n",
       "        3.0265776e-03], dtype=float32),\n",
       " array([0.02223878, 0.08878738, 0.13526037, 0.38513014, 0.16392007,\n",
       "        0.03665195, 0.04821116, 0.02055687, 0.0375403 , 0.00375665,\n",
       "        0.00350813, 0.00359901, 0.0016342 , 0.04217507, 0.00198632,\n",
       "        0.0032811 , 0.00176259], dtype=float32),\n",
       " array([3.3544764e-02, 7.5046338e-02, 8.4128618e-02, 4.0028596e-01,\n",
       "        2.4471100e-01, 2.3722602e-04, 6.3429192e-02, 5.6496440e-03,\n",
       "        4.4987231e-02, 5.5371295e-03, 1.1898980e-03, 1.4209958e-03,\n",
       "        1.1451910e-03, 3.0940576e-02, 8.1777066e-04, 1.5181565e-03,\n",
       "        5.4103131e-03], dtype=float32),\n",
       " array([0.023283  , 0.07611811, 0.21185021, 0.37537605, 0.09600208,\n",
       "        0.00062184, 0.05779802, 0.01206338, 0.07920396, 0.00854306,\n",
       "        0.00189462, 0.00158989, 0.00169232, 0.04557759, 0.00261518,\n",
       "        0.00456333, 0.00120737], dtype=float32),\n",
       " array([0.02790291, 0.10636839, 0.09855074, 0.46681666, 0.09628647,\n",
       "        0.0013566 , 0.03192765, 0.02224936, 0.08943406, 0.00872365,\n",
       "        0.00291219, 0.0024649 , 0.00077508, 0.0346331 , 0.00388552,\n",
       "        0.0030046 , 0.00270807], dtype=float32),\n",
       " array([2.0273887e-02, 9.9233463e-02, 5.6462539e-03, 5.6912255e-01,\n",
       "        1.8497111e-01, 8.2993734e-05, 1.4541679e-02, 7.3818886e-03,\n",
       "        7.7114791e-02, 6.6806404e-03, 1.1392013e-03, 4.9800507e-04,\n",
       "        2.1311370e-04, 7.0254388e-03, 1.0055806e-03, 6.8873976e-04,\n",
       "        4.3806848e-03], dtype=float32),\n",
       " array([2.4428902e-02, 7.2587594e-02, 1.3659987e-02, 5.9056401e-01,\n",
       "        1.6779231e-01, 1.2580538e-04, 2.2524225e-02, 1.8065441e-02,\n",
       "        6.0895957e-02, 8.7130591e-03, 9.0181333e-04, 6.0814485e-04,\n",
       "        5.4619700e-04, 8.1420522e-03, 1.5583273e-03, 3.2430324e-03,\n",
       "        5.6430828e-03], dtype=float32),\n",
       " array([2.8500147e-02, 7.9212852e-02, 4.7969263e-02, 4.9399906e-01,\n",
       "        1.7109177e-01, 1.7123522e-04, 4.3605074e-02, 8.1834402e-03,\n",
       "        6.7790881e-02, 1.5914638e-02, 9.4331481e-04, 1.6606495e-03,\n",
       "        7.7374984e-04, 3.5204425e-02, 9.1409934e-04, 6.6257420e-04,\n",
       "        3.4027982e-03], dtype=float32),\n",
       " array([1.9643949e-02, 6.5557279e-02, 7.6861419e-02, 3.9798942e-01,\n",
       "        2.7297014e-01, 3.4308535e-04, 2.3548231e-02, 1.8022517e-02,\n",
       "        8.5526511e-02, 7.6117436e-03, 1.5110528e-03, 1.0910757e-03,\n",
       "        1.5511954e-03, 1.8525988e-02, 3.1771413e-03, 4.2577125e-03,\n",
       "        1.8115485e-03], dtype=float32),\n",
       " array([2.0803621e-02, 7.3333614e-02, 8.0168702e-02, 4.9997681e-01,\n",
       "        1.9286846e-01, 1.6145878e-04, 2.0004466e-02, 2.1977171e-02,\n",
       "        5.1087309e-02, 6.1729234e-03, 9.6859992e-04, 1.6187712e-03,\n",
       "        5.8532663e-04, 1.9927636e-02, 8.6138572e-04, 2.4887195e-03,\n",
       "        6.9951327e-03], dtype=float32),\n",
       " array([2.1598071e-02, 8.3457828e-02, 0.0000000e+00, 6.9689882e-01,\n",
       "        7.7495337e-02, 9.5408672e-05, 1.5951838e-02, 9.3818977e-03,\n",
       "        7.1679376e-02, 6.3325297e-03, 1.1813928e-03, 7.7861454e-04,\n",
       "        5.1494723e-04, 8.0720615e-03, 8.0062891e-04, 5.1902048e-04,\n",
       "        5.2422299e-03], dtype=float32),\n",
       " array([0.02762054, 0.09538261, 0.        , 0.44823328, 0.1904174 ,\n",
       "        0.05301403, 0.05448345, 0.01914789, 0.04870904, 0.00536403,\n",
       "        0.00268355, 0.00538551, 0.00121   , 0.04183083, 0.00160669,\n",
       "        0.00356144, 0.00134965], dtype=float32),\n",
       " array([2.89694164e-02, 6.81463331e-02, 1.17788345e-01, 4.59962875e-01,\n",
       "        1.93385527e-01, 4.36575996e-04, 4.20515463e-02, 2.25112750e-03,\n",
       "        3.01563535e-02, 8.46129563e-03, 1.15054252e-03, 1.02498278e-03,\n",
       "        4.63539996e-04, 3.19955796e-02, 2.77965562e-03, 4.66373330e-03,\n",
       "        6.31261710e-03], dtype=float32),\n",
       " array([0.02381502, 0.06617536, 0.07924567, 0.42128685, 0.21642596,\n",
       "        0.00309642, 0.02955059, 0.02206655, 0.08276457, 0.0090705 ,\n",
       "        0.00223281, 0.00203453, 0.00121452, 0.02981116, 0.00372329,\n",
       "        0.00505961, 0.00242656], dtype=float32),\n",
       " array([2.8975971e-02, 6.8161748e-02, 1.1781500e-01, 4.6006697e-01,\n",
       "        1.9342929e-01, 4.3667480e-04, 4.2061064e-02, 2.2267632e-03,\n",
       "        3.0163178e-02, 8.3160345e-03, 1.1335060e-03, 1.0166758e-03,\n",
       "        4.6164880e-04, 3.2002822e-02, 2.7538110e-03, 4.6647890e-03,\n",
       "        6.3140457e-03], dtype=float32),\n",
       " array([0.02820475, 0.11181956, 0.10625767, 0.44040778, 0.10381634,\n",
       "        0.00146269, 0.03442447, 0.02398932, 0.08781847, 0.00908884,\n",
       "        0.00297297, 0.00262224, 0.00083292, 0.03614978, 0.00416459,\n",
       "        0.00312307, 0.00284452], dtype=float32),\n",
       " array([2.3900351e-02, 8.8239312e-02, 0.0000000e+00, 6.9727546e-01,\n",
       "        5.2687071e-02, 1.5143078e-04, 1.7061409e-02, 6.1521181e-03,\n",
       "        9.2131481e-02, 5.9342841e-03, 8.7634148e-04, 4.8954238e-04,\n",
       "        2.6551037e-04, 7.3736939e-03, 1.0630246e-03, 4.8551802e-04,\n",
       "        5.9134439e-03], dtype=float32),\n",
       " array([0.03209844, 0.0554444 , 0.0809053 , 0.39868742, 0.2642399 ,\n",
       "        0.00057148, 0.07922826, 0.00393567, 0.03970907, 0.00702988,\n",
       "        0.00137725, 0.00107404, 0.0007461 , 0.0242247 , 0.00252498,\n",
       "        0.00439757, 0.00380558], dtype=float32),\n",
       " array([0.03032704, 0.07486437, 0.07584966, 0.47518894, 0.11757671,\n",
       "        0.0396026 , 0.05799493, 0.01902561, 0.05713695, 0.00722827,\n",
       "        0.00285613, 0.00313725, 0.00159313, 0.03137968, 0.00265998,\n",
       "        0.0023561 , 0.00122261], dtype=float32),\n",
       " array([2.3079727e-02, 7.0718326e-02, 4.9347248e-02, 4.8898920e-01,\n",
       "        2.0438612e-01, 3.0321485e-04, 2.8092513e-02, 1.6775794e-02,\n",
       "        7.3098645e-02, 9.6179014e-03, 1.6098783e-03, 1.1148283e-03,\n",
       "        1.4247416e-03, 1.9713573e-02, 2.9207598e-03, 3.5641675e-03,\n",
       "        5.2434886e-03], dtype=float32),\n",
       " array([1.5345571e-02, 7.3497921e-02, 1.3099072e-02, 7.4335581e-01,\n",
       "        5.3305745e-02, 7.3604817e-05, 1.0819907e-02, 9.6397158e-03,\n",
       "        6.1108850e-02, 5.9539708e-03, 6.9178792e-04, 4.8796504e-04,\n",
       "        3.3407618e-04, 6.0249236e-03, 1.2308265e-03, 4.2382357e-04,\n",
       "        4.6065366e-03], dtype=float32),\n",
       " array([0.0264778 , 0.07168247, 0.09810449, 0.40402305, 0.17082043,\n",
       "        0.02351605, 0.03306402, 0.02749919, 0.08410183, 0.01082633,\n",
       "        0.00257549, 0.00211277, 0.00161526, 0.03633672, 0.00306216,\n",
       "        0.00185704, 0.00232489], dtype=float32),\n",
       " array([3.2559242e-02, 6.1234947e-02, 9.8040663e-02, 3.5021025e-01,\n",
       "        2.6669937e-01, 3.2922992e-04, 7.4631393e-02, 7.6423748e-03,\n",
       "        6.1918564e-02, 4.9065924e-03, 1.5216345e-03, 8.8431808e-04,\n",
       "        1.2039942e-03, 3.0568285e-02, 1.2223605e-03, 8.6923724e-04,\n",
       "        5.5575934e-03], dtype=float32),\n",
       " array([0.03080448, 0.06993052, 0.2244817 , 0.37205347, 0.08682391,\n",
       "        0.00083945, 0.05904533, 0.01769652, 0.07040083, 0.00602457,\n",
       "        0.00290214, 0.00217143, 0.00215302, 0.04185094, 0.00667013,\n",
       "        0.00413698, 0.00201458], dtype=float32),\n",
       " array([0.01513421, 0.06596313, 0.10540824, 0.3675808 , 0.29322106,\n",
       "        0.00044723, 0.02601712, 0.01582661, 0.07384524, 0.00550461,\n",
       "        0.00185959, 0.00080493, 0.00134369, 0.01740297, 0.0029221 ,\n",
       "        0.00355501, 0.00316352], dtype=float32),\n",
       " array([0.02837271, 0.0545912 , 0.1199354 , 0.37457705, 0.25083834,\n",
       "        0.00042803, 0.07277361, 0.00565166, 0.04634597, 0.00528241,\n",
       "        0.00149477, 0.00075906, 0.00084008, 0.03013655, 0.00116943,\n",
       "        0.00212288, 0.00468088], dtype=float32),\n",
       " array([0.03151095, 0.06676565, 0.0724329 , 0.3848183 , 0.20189387,\n",
       "        0.05023665, 0.04636624, 0.01348518, 0.07697415, 0.00865603,\n",
       "        0.00317477, 0.00363168, 0.0015075 , 0.0306634 , 0.00480673,\n",
       "        0.00174521, 0.00133083], dtype=float32),\n",
       " array([2.7146675e-02, 8.6536691e-02, 0.0000000e+00, 5.7574219e-01,\n",
       "        1.3804857e-01, 1.2025367e-04, 2.0929165e-02, 1.9553520e-02,\n",
       "        9.9690825e-02, 9.7794132e-03, 1.5353961e-03, 5.4700283e-04,\n",
       "        8.9972123e-04, 9.5210038e-03, 1.9085901e-03, 9.8146265e-04,\n",
       "        7.0595942e-03], dtype=float32),\n",
       " array([0.03343744, 0.05065027, 0.06467105, 0.38242394, 0.28162402,\n",
       "        0.00073237, 0.07861591, 0.00519435, 0.04882783, 0.00956998,\n",
       "        0.00151801, 0.00131974, 0.00092754, 0.02824409, 0.00287438,\n",
       "        0.0048166 , 0.00455255], dtype=float32),\n",
       " array([2.7382115e-02, 8.3865017e-02, 1.7433240e-01, 4.0774968e-01,\n",
       "        1.8234837e-01, 1.2180165e-04, 5.2642386e-02, 5.0315382e-03,\n",
       "        2.4777396e-02, 6.3554673e-03, 9.6476014e-04, 5.9266581e-04,\n",
       "        1.1275030e-03, 2.6133044e-02, 1.0687932e-03, 5.4806937e-04,\n",
       "        4.9589691e-03], dtype=float32),\n",
       " array([0.02855551, 0.0635732 , 0.07134412, 0.43529484, 0.20632231,\n",
       "        0.01041439, 0.03214888, 0.02362792, 0.08295928, 0.00575944,\n",
       "        0.00230268, 0.00163249, 0.0014597 , 0.02579852, 0.00152601,\n",
       "        0.00139372, 0.00588698], dtype=float32),\n",
       " array([0.01901208, 0.05283337, 0.14995362, 0.39578408, 0.23876086,\n",
       "        0.00136616, 0.02376242, 0.01591239, 0.05900682, 0.00741091,\n",
       "        0.00202524, 0.00106628, 0.00071978, 0.02063101, 0.00268706,\n",
       "        0.00718285, 0.00188513], dtype=float32),\n",
       " array([3.4209408e-02, 7.5933799e-02, 1.9611096e-05, 4.9311396e-01,\n",
       "        1.9845521e-01, 3.6648005e-02, 5.1695161e-02, 1.4883991e-02,\n",
       "        3.6718443e-02, 5.9249792e-03, 3.1612720e-03, 3.5975922e-03,\n",
       "        1.5383237e-03, 3.7263032e-02, 2.4361054e-03, 3.1815825e-03,\n",
       "        1.2194796e-03], dtype=float32),\n",
       " array([2.6632303e-02, 7.7389851e-02, 9.8695338e-02, 3.8372070e-01,\n",
       "        2.4321762e-01, 2.4103926e-04, 6.6299722e-02, 5.6705740e-03,\n",
       "        5.1053919e-02, 8.5624726e-03, 9.8704209e-04, 7.3229638e-04,\n",
       "        1.1194927e-03, 2.7429324e-02, 1.1224045e-03, 1.4488734e-03,\n",
       "        5.6770467e-03], dtype=float32),\n",
       " array([0.03227109, 0.0923394 , 0.0581339 , 0.36550957, 0.21321994,\n",
       "        0.0532401 , 0.05357407, 0.01936239, 0.04874022, 0.00680677,\n",
       "        0.00390468, 0.00592775, 0.00131133, 0.03836831, 0.00187457,\n",
       "        0.00333269, 0.00208328], dtype=float32),\n",
       " array([2.4591874e-02, 6.9108084e-02, 3.4950820e-01, 3.6721918e-01,\n",
       "        5.1037543e-02, 1.7243608e-04, 3.8044557e-02, 1.0384326e-02,\n",
       "        3.5263333e-02, 4.3565114e-03, 1.1746560e-03, 1.3776041e-03,\n",
       "        1.8310389e-03, 3.6974348e-02, 4.7910893e-03, 2.1889950e-03,\n",
       "        1.9762327e-03], dtype=float32),\n",
       " array([0.02349425, 0.07759951, 0.04846329, 0.52524346, 0.09901949,\n",
       "        0.04515442, 0.05226557, 0.017207  , 0.05649484, 0.00821167,\n",
       "        0.00278589, 0.00374174, 0.0008716 , 0.03402616, 0.00222368,\n",
       "        0.00211659, 0.00108082], dtype=float32),\n",
       " array([1.62011050e-02, 7.96369016e-02, 4.24790718e-02, 6.67983055e-01,\n",
       "        8.25882107e-02, 9.75501898e-05, 1.50303375e-02, 8.35198909e-03,\n",
       "        6.79812804e-02, 6.00260869e-03, 9.11095471e-04, 5.31516795e-04,\n",
       "        2.29644575e-04, 7.34381564e-03, 4.17794770e-04, 3.67706933e-04,\n",
       "        3.84627748e-03], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fb13819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1731420499665705, 0.2413373771422086)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(rmse_values_test), np.max(rmse_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bb42d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0004238698282987489, 0.0171040255713061)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(rmse_values_train), np.max(rmse_values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15bfc47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 0.20169122405613596\n"
     ]
    }
   ],
   "source": [
    "mean_rmse_test = np.mean(rmse_values_test)\n",
    "print(f\"Mean RMSE: {mean_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44b626f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 0.0017953509682206998\n"
     ]
    }
   ],
   "source": [
    "mean_rmse_train = np.mean(rmse_values_train)\n",
    "print(f\"Mean RMSE: {mean_rmse_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8eba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.best_estimator_.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a838d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(x=range(36), height=np.mean(feature_importances, axis=0), yerr=np.std(feature_importances, axis=0))\n",
    "plt.xticks(ticks = range(36), labels=X_train.columns, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clf.best_estimator_.feature_importances_)\n",
    "[0]*24\n",
    "\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945911e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"neg_MSE:\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.best_estimator_.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "rmse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea51a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = clf.best_estimator_.predict(X_train)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(y_train, y_train_predict, facecolors='black', edgecolors='black', s=10)\n",
    "plt.scatter(y_test, y_predict, marker='s', edgecolors='red',facecolors='pink' ,s=15)\n",
    "plt.plot([-1,2], [-1,2],)\n",
    "plt.grid(True)\n",
    "plt.xlabel('DFT-calculated')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('(d)_0.30')\n",
    "\n",
    "plt.show\n",
    "plt.savefig('DFT vs predicted_OH - test_size_0.30_xGBR.jpg',dpi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = clf.best_estimator_.predict(X_train)\n",
    "plt.figure(figsize=(12, 8),dpi=400)\n",
    "plt.scatter(y_train, y_train_predict, facecolors='black', edgecolors='black', s=30)\n",
    "plt.scatter(y_test, y_predict, marker='s', edgecolors='red',facecolors='pink' ,s=35)\n",
    "plt.plot([-1,3], [-1,3],)\n",
    "plt.grid(False)\n",
    "plt.xlabel('DFT-calculated', fontsize=25)\n",
    "plt.ylabel('Predicted', fontsize=25)\n",
    "plt.title('(d) - Train/Test = 0.70/0.30 ', fontsize=25)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.show\n",
    "plt.savefig('DFT vs predicted(xGBR) - test_size_0.30.jpg',dpi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b76f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = clf.best_estimator_.predict(x)\n",
    "t = pd.DataFrame(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_OH = 'output_data_OH_xgbr_0.30.xlsx'\n",
    "t.to_excel(output_file_OH, index=False)\n",
    "print(f\"Data frame converted and saved to '{output_file_OH}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e30d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.feature_importances_\n",
    "plt.figure(figsize=(12, 8))\n",
    "feat_importances = pd.Series(clf.best_estimator_.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='bar')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance - scale (0-1)')\n",
    "plt.show()\n",
    "plt.savefig('Feature_Importance_best_esti_xgbr_(0.30).jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is your feature matrix and clf is your trained classifier\n",
    "# Replace 'dog' and 'cat' with the actual feature names you want to exclude\n",
    "features_to_exclude = []\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.best_estimator_.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature importances\n",
    "feat_importances = pd.Series(importances, index=X.columns)\n",
    "\n",
    "# Drop the specified features\n",
    "feat_importances = feat_importances.drop(features_to_exclude, errors='ignore')\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "feat_importances.nlargest(20).plot(kind='bar')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance - scale (0-1)')\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Feature_Importance_remaining_xgbr_(0.30).jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg=np.mean(feature_importances, axis=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "feat_importances = pd.Series(avg, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='bar')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance - scale (0-1)')\n",
    "plt.show()\n",
    "plt.savefig('Feature_Importance_average_xgbr_(0.30).jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "med=np.median(feature_importances, axis=0)\n",
    "feat_importances = pd.Series(med, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bf933",
   "metadata": {},
   "outputs": [],
   "source": [
    "std=np.std(feature_importances, axis=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "feat_importances = pd.Series(std, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.show()\n",
    "plt.savefig('standard deviation_xgbr_(0.30).jpg', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf395f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0d618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
