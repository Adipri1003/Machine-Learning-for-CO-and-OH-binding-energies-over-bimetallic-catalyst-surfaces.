{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b91116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b1bbea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>...</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "      <th>Carbon_B.E</th>\n",
       "      <th>Oxygen_B.E</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ag3Ag</td>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3100</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.65</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.630</td>\n",
       "      <td>125.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ag3Cd</td>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6780</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ag3Pd</td>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0440</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.69</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.470</td>\n",
       "      <td>53.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ag3Pt</td>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7000</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.77</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.970</td>\n",
       "      <td>205.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As3As</td>\n",
       "      <td>33</td>\n",
       "      <td>74.900</td>\n",
       "      <td>5.727</td>\n",
       "      <td>1090.00</td>\n",
       "      <td>887</td>\n",
       "      <td>27.7</td>\n",
       "      <td>302</td>\n",
       "      <td>32.4</td>\n",
       "      <td>328.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4700</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.439</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Co3Ru</td>\n",
       "      <td>27</td>\n",
       "      <td>58.933</td>\n",
       "      <td>8.900</td>\n",
       "      <td>1768.00</td>\n",
       "      <td>3200</td>\n",
       "      <td>16.2</td>\n",
       "      <td>426</td>\n",
       "      <td>375.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.1020</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.78</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.650</td>\n",
       "      <td>101.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Cu3Rh</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.960</td>\n",
       "      <td>1357.00</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300.0</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.1970</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.73</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.200</td>\n",
       "      <td>109.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Ni3Cu</td>\n",
       "      <td>28</td>\n",
       "      <td>58.693</td>\n",
       "      <td>8.908</td>\n",
       "      <td>1728.00</td>\n",
       "      <td>3186</td>\n",
       "      <td>17.2</td>\n",
       "      <td>431</td>\n",
       "      <td>378.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4550</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.090</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Pt3Au</td>\n",
       "      <td>78</td>\n",
       "      <td>195.080</td>\n",
       "      <td>21.450</td>\n",
       "      <td>2041.40</td>\n",
       "      <td>4098</td>\n",
       "      <td>20.0</td>\n",
       "      <td>565</td>\n",
       "      <td>490.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9013</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.410</td>\n",
       "      <td>222.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Cu3Cd</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.960</td>\n",
       "      <td>1357.00</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300.0</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6780</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Element  M-At No.  M-At wt.  M-Density    M-M.P  M-B.P  M-Enth.fus  \\\n",
       "0     Ag3Ag        47   107.870     10.490  1234.93   2435        11.3   \n",
       "1     Ag3Cd        47   107.870     10.490  1234.93   2435        11.3   \n",
       "2     Ag3Pd        47   107.870     10.490  1234.93   2435        11.3   \n",
       "3     Ag3Pt        47   107.870     10.490  1234.93   2435        11.3   \n",
       "4     As3As        33    74.900      5.727  1090.00    887        27.7   \n",
       "..      ...       ...       ...        ...      ...    ...         ...   \n",
       "240   Co3Ru        27    58.933      8.900  1768.00   3200        16.2   \n",
       "241   Cu3Rh        29    63.546      8.960  1357.00   2835        13.1   \n",
       "242   Ni3Cu        28    58.693      8.908  1728.00   3186        17.2   \n",
       "243   Pt3Au        78   195.080     21.450  2041.40   4098        20.0   \n",
       "244   Cu3Cd        29    63.546      8.960  1357.00   2835        13.1   \n",
       "\n",
       "     M-Enth.atom  M-Enth.vap  M-Sp.ht Cap  ...  1st Ion E  cova .radii  \\\n",
       "0            285       255.0        235.0  ...     7.3100         1.45   \n",
       "1            285       255.0        235.0  ...     8.6780         1.44   \n",
       "2            285       255.0        235.0  ...     8.0440         1.31   \n",
       "3            285       255.0        235.0  ...     8.7000         1.36   \n",
       "4            302        32.4        328.0  ...     9.4700         1.19   \n",
       "..           ...         ...          ...  ...        ...          ...   \n",
       "240          426       375.0        421.0  ...     7.1020         1.26   \n",
       "241          338       300.0        384.4  ...     7.1970         1.35   \n",
       "242          431       378.0        445.0  ...     7.4550         1.32   \n",
       "243          565       490.0        133.0  ...     8.9013         1.36   \n",
       "244          338       300.0        384.4  ...     8.6780         1.44   \n",
       "\n",
       "     At.radii  Group  Period  Work F.  Elec.Aff  Carbon_B.E  Oxygen_B.E  \\\n",
       "0        1.65   11.0       5    4.630     125.6         5.1         2.0   \n",
       "1        1.61   12.0       5    3.634       0.0         4.9         1.6   \n",
       "2        1.69   10.0       5    5.470      53.7         3.9         2.1   \n",
       "3        1.77   10.0       6    5.970     205.3         2.9         1.8   \n",
       "4        1.14   15.0       4    4.439      78.0         1.5        -0.7   \n",
       "..        ...    ...     ...      ...       ...         ...         ...   \n",
       "240      1.78    8.0       5    4.650     101.3         1.4        -0.1   \n",
       "241      1.73    9.0       5    5.200     109.7         1.2         0.6   \n",
       "242      1.45   11.0       4    5.090     118.4         1.6         0.2   \n",
       "243      1.74   11.0       6    5.410     222.8         2.2         1.8   \n",
       "244      1.61   12.0       5    3.634       0.0         3.8         1.1   \n",
       "\n",
       "    Unnamed: 40  \n",
       "0         100.0  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "..          ...  \n",
       "240         NaN  \n",
       "241         NaN  \n",
       "242         NaN  \n",
       "243         NaN  \n",
       "244         NaN  \n",
       "\n",
       "[245 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('C_and_O_Bindings_A3B_AA_terminated_Modified.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900236db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>...</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "      <th>Carbon_B.E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.3100</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.65</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.630</td>\n",
       "      <td>125.6</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.6780</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>8.0440</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.69</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.470</td>\n",
       "      <td>53.7</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>107.870</td>\n",
       "      <td>10.490</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>8.7000</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.77</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.970</td>\n",
       "      <td>205.3</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>74.900</td>\n",
       "      <td>5.727</td>\n",
       "      <td>1090.00</td>\n",
       "      <td>887</td>\n",
       "      <td>27.7</td>\n",
       "      <td>302</td>\n",
       "      <td>32.4</td>\n",
       "      <td>328.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>...</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.4700</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.439</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27</td>\n",
       "      <td>58.933</td>\n",
       "      <td>8.900</td>\n",
       "      <td>1768.00</td>\n",
       "      <td>3200</td>\n",
       "      <td>16.2</td>\n",
       "      <td>426</td>\n",
       "      <td>375.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>7.1020</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.78</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.650</td>\n",
       "      <td>101.3</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.960</td>\n",
       "      <td>1357.00</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300.0</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.90</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.98</td>\n",
       "      <td>7.1970</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.73</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.200</td>\n",
       "      <td>109.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>28</td>\n",
       "      <td>58.693</td>\n",
       "      <td>8.908</td>\n",
       "      <td>1728.00</td>\n",
       "      <td>3186</td>\n",
       "      <td>17.2</td>\n",
       "      <td>431</td>\n",
       "      <td>378.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.34</td>\n",
       "      <td>7.4550</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.090</td>\n",
       "      <td>118.4</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>78</td>\n",
       "      <td>195.080</td>\n",
       "      <td>21.450</td>\n",
       "      <td>2041.40</td>\n",
       "      <td>4098</td>\n",
       "      <td>20.0</td>\n",
       "      <td>565</td>\n",
       "      <td>490.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>8.9013</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.410</td>\n",
       "      <td>222.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.960</td>\n",
       "      <td>1357.00</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300.0</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.6780</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     M-At No.  M-At wt.  M-Density    M-M.P  M-B.P  M-Enth.fus  M-Enth.atom  \\\n",
       "0          47   107.870     10.490  1234.93   2435        11.3          285   \n",
       "1          47   107.870     10.490  1234.93   2435        11.3          285   \n",
       "2          47   107.870     10.490  1234.93   2435        11.3          285   \n",
       "3          47   107.870     10.490  1234.93   2435        11.3          285   \n",
       "4          33    74.900      5.727  1090.00    887        27.7          302   \n",
       "..        ...       ...        ...      ...    ...         ...          ...   \n",
       "240        27    58.933      8.900  1768.00   3200        16.2          426   \n",
       "241        29    63.546      8.960  1357.00   2835        13.1          338   \n",
       "242        28    58.693      8.908  1728.00   3186        17.2          431   \n",
       "243        78   195.080     21.450  2041.40   4098        20.0          565   \n",
       "244        29    63.546      8.960  1357.00   2835        13.1          338   \n",
       "\n",
       "     M-Enth.vap  M-Sp.ht Cap  M-Elec.-ve  ...  Elec.-ve  Surface.E  1st Ion E  \\\n",
       "0         255.0        235.0        1.93  ...      1.93       0.76     7.3100   \n",
       "1         255.0        235.0        1.93  ...      1.69       0.16     8.6780   \n",
       "2         255.0        235.0        1.93  ...      2.20       1.36     8.0440   \n",
       "3         255.0        235.0        1.93  ...      2.28       1.49     8.7000   \n",
       "4          32.4        328.0        2.18  ...      2.18       0.09     9.4700   \n",
       "..          ...          ...         ...  ...       ...        ...        ...   \n",
       "240       375.0        421.0        1.88  ...      2.20       2.60     7.1020   \n",
       "241       300.0        384.4        1.90  ...      2.28       1.98     7.1970   \n",
       "242       378.0        445.0        1.91  ...      1.90       1.34     7.4550   \n",
       "243       490.0        133.0        2.28  ...      2.54       0.74     8.9013   \n",
       "244       300.0        384.4        1.90  ...      1.69       0.16     8.6780   \n",
       "\n",
       "     cova .radii  At.radii  Group  Period  Work F. Elec.Aff  Carbon_B.E  \n",
       "0           1.45      1.65   11.0       5    4.630    125.6         5.1  \n",
       "1           1.44      1.61   12.0       5    3.634      0.0         4.9  \n",
       "2           1.31      1.69   10.0       5    5.470     53.7         3.9  \n",
       "3           1.36      1.77   10.0       6    5.970    205.3         2.9  \n",
       "4           1.19      1.14   15.0       4    4.439     78.0         1.5  \n",
       "..           ...       ...    ...     ...      ...      ...         ...  \n",
       "240         1.26      1.78    8.0       5    4.650    101.3         1.4  \n",
       "241         1.35      1.73    9.0       5    5.200    109.7         1.2  \n",
       "242         1.32      1.45   11.0       4    5.090    118.4         1.6  \n",
       "243         1.36      1.74   11.0       6    5.410    222.8         2.2  \n",
       "244         1.44      1.61   12.0       5    3.634      0.0         3.8  \n",
       "\n",
       "[245 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.iloc[:,1:39]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc4165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M-At No.', 'M-At wt.', 'M-Density', 'M-M.P', 'M-B.P', 'M-Enth.fus', 'M-Enth.atom', 'M-Enth.vap', 'M-Sp.ht Cap', 'M-Elec.-ve', 'M-Surface.E', 'M-1st Ion E', 'M-cova .radii', 'M-At.radii', 'M-Group', 'M-Period', 'M-Work F.', 'M-Elec.Aff', 'Ele', 'At No.', 'At wt.', 'Density', 'M.P', 'B.P', 'Enth.fus', 'Enth.atom', 'Enth.vap', 'Sp.ht Cap', 'Elec.-ve', 'Surface.E', '1st Ion E', 'cova .radii', 'At.radii', 'Group', 'Period', 'Work F.', 'Elec.Aff', 'Carbon_B.E']\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d45ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df2\n",
    "y= df['Carbon_B.E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d9d8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((171, 38), (74, 38))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e17648",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9dc1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>M-Surface.E</th>\n",
       "      <th>M-1st Ion E</th>\n",
       "      <th>M-cova .radii</th>\n",
       "      <th>...</th>\n",
       "      <th>Enth.fus</th>\n",
       "      <th>Enth.atom</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.870</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.310</td>\n",
       "      <td>1.45</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.3100</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.65</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.630</td>\n",
       "      <td>125.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.870</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.310</td>\n",
       "      <td>1.45</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>112</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.6780</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.870</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.310</td>\n",
       "      <td>1.45</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7</td>\n",
       "      <td>377</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>8.0440</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.69</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.470</td>\n",
       "      <td>53.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.870</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>255.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7.310</td>\n",
       "      <td>1.45</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>565</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>8.7000</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.77</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.970</td>\n",
       "      <td>205.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.900</td>\n",
       "      <td>1090.00</td>\n",
       "      <td>887</td>\n",
       "      <td>27.7</td>\n",
       "      <td>32.4</td>\n",
       "      <td>328.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.470</td>\n",
       "      <td>1.19</td>\n",
       "      <td>...</td>\n",
       "      <td>27.7</td>\n",
       "      <td>302</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.4700</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.439</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>58.933</td>\n",
       "      <td>1768.00</td>\n",
       "      <td>3200</td>\n",
       "      <td>16.2</td>\n",
       "      <td>375.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.11</td>\n",
       "      <td>7.604</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7</td>\n",
       "      <td>652</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>7.1020</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.78</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.650</td>\n",
       "      <td>101.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>63.546</td>\n",
       "      <td>1357.00</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.34</td>\n",
       "      <td>7.455</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>21.7</td>\n",
       "      <td>556</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.98</td>\n",
       "      <td>7.1970</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.73</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.200</td>\n",
       "      <td>109.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>58.693</td>\n",
       "      <td>1728.00</td>\n",
       "      <td>3186</td>\n",
       "      <td>17.2</td>\n",
       "      <td>378.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7.371</td>\n",
       "      <td>1.21</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.34</td>\n",
       "      <td>7.4550</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.090</td>\n",
       "      <td>118.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>195.080</td>\n",
       "      <td>2041.40</td>\n",
       "      <td>4098</td>\n",
       "      <td>20.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>8.700</td>\n",
       "      <td>1.36</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>368</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>8.9013</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.410</td>\n",
       "      <td>222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>63.546</td>\n",
       "      <td>1357.00</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.34</td>\n",
       "      <td>7.455</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>112</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.6780</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     M-At wt.    M-M.P  M-B.P  M-Enth.fus  M-Enth.vap  M-Sp.ht Cap  \\\n",
       "0     107.870  1234.93   2435        11.3       255.0        235.0   \n",
       "1     107.870  1234.93   2435        11.3       255.0        235.0   \n",
       "2     107.870  1234.93   2435        11.3       255.0        235.0   \n",
       "3     107.870  1234.93   2435        11.3       255.0        235.0   \n",
       "4      74.900  1090.00    887        27.7        32.4        328.0   \n",
       "..        ...      ...    ...         ...         ...          ...   \n",
       "240    58.933  1768.00   3200        16.2       375.0        421.0   \n",
       "241    63.546  1357.00   2835        13.1       300.0        384.4   \n",
       "242    58.693  1728.00   3186        17.2       378.0        445.0   \n",
       "243   195.080  2041.40   4098        20.0       490.0        133.0   \n",
       "244    63.546  1357.00   2835        13.1       300.0        384.4   \n",
       "\n",
       "     M-Elec.-ve  M-Surface.E  M-1st Ion E  M-cova .radii  ...  Enth.fus  \\\n",
       "0          1.93         0.76        7.310           1.45  ...      11.3   \n",
       "1          1.93         0.76        7.310           1.45  ...       6.3   \n",
       "2          1.93         0.76        7.310           1.45  ...      16.7   \n",
       "3          1.93         0.76        7.310           1.45  ...      20.0   \n",
       "4          2.18         0.09        9.470           1.19  ...      27.7   \n",
       "..          ...          ...          ...            ...  ...       ...   \n",
       "240        1.88         2.11        7.604           1.26  ...      25.7   \n",
       "241        1.90         1.34        7.455           1.32  ...      21.7   \n",
       "242        1.91         1.92        7.371           1.21  ...      13.1   \n",
       "243        2.28         1.49        8.700           1.36  ...      12.5   \n",
       "244        1.90         1.34        7.455           1.32  ...       6.3   \n",
       "\n",
       "     Enth.atom  Elec.-ve  Surface.E  1st Ion E  cova .radii  At.radii  Group  \\\n",
       "0          285      1.93       0.76     7.3100         1.45      1.65   11.0   \n",
       "1          112      1.69       0.16     8.6780         1.44      1.61   12.0   \n",
       "2          377      2.20       1.36     8.0440         1.31      1.69   10.0   \n",
       "3          565      2.28       1.49     8.7000         1.36      1.77   10.0   \n",
       "4          302      2.18       0.09     9.4700         1.19      1.14   15.0   \n",
       "..         ...       ...        ...        ...          ...       ...    ...   \n",
       "240        652      2.20       2.60     7.1020         1.26      1.78    8.0   \n",
       "241        556      2.28       1.98     7.1970         1.35      1.73    9.0   \n",
       "242        338      1.90       1.34     7.4550         1.32      1.45   11.0   \n",
       "243        368      2.54       0.74     8.9013         1.36      1.74   11.0   \n",
       "244        112      1.69       0.16     8.6780         1.44      1.61   12.0   \n",
       "\n",
       "     Work F.  Elec.Aff  \n",
       "0      4.630     125.6  \n",
       "1      3.634       0.0  \n",
       "2      5.470      53.7  \n",
       "3      5.970     205.3  \n",
       "4      4.439      78.0  \n",
       "..       ...       ...  \n",
       "240    4.650     101.3  \n",
       "241    5.200     109.7  \n",
       "242    5.090     118.4  \n",
       "243    5.410     222.8  \n",
       "244    3.634       0.0  \n",
       "\n",
       "[245 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.drop(labels=[\"Carbon_B.E\",\"Ele\",'M-Enth.atom','M-Work F.', 'M-Elec.Aff',\n",
    "                         'Enth.vap', 'Sp.ht Cap','M-At No.','M-Density','At No.', 'At wt.','Period','M-Period',\n",
    "                      ], axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ce92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M-At wt.', 'M-M.P', 'M-B.P', 'M-Enth.fus', 'M-Enth.vap', 'M-Sp.ht Cap', 'M-Elec.-ve', 'M-Surface.E', 'M-1st Ion E', 'M-cova .radii', 'M-At.radii', 'M-Group', 'Density', 'M.P', 'B.P', 'Enth.fus', 'Enth.atom', 'Elec.-ve', 'Surface.E', '1st Ion E', 'cova .radii', 'At.radii', 'Group', 'Work F.', 'Elec.Aff']\n"
     ]
    }
   ],
   "source": [
    "print(df3.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba48fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df3\n",
    "y= df['Carbon_B.E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8183bc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((196, 25), (49, 25))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9289beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on test data is 0.8918320939722997\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "print(\"r2 on test data is\",   r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b6839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:0.3970645310350559\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\"+str(np.sqrt(mean_squared_error(y_test, y_predict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df550b69",
   "metadata": {},
   "source": [
    "selected_feature_list = ['M-1st Ion E', 'M-cova .radii','M-Period','cova .radii', 'Period']\n",
    "\n",
    "# Define the 26 features that remain unchanged\n",
    "fixed_features = ['M-At wt.', 'M-M.P', 'M-B.P', 'M-Enth.fus', 'M-Enth.vap', 'M-Sp.ht Cap', 'M-Elec.-ve', 'M-Surface.E', 'M-At.radii', 'M-Group', 'Density', 'M.P', 'B.P', 'Enth.fus', 'Enth.atom', 'Elec.-ve', 'Surface.E', '1st Ion E', 'At.radii', 'Group', 'Work F.', 'Elec.Aff']\n",
    "\n",
    "# Load dataset (Assuming df is already defined)\n",
    "y = df['Carbon_B.E']\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_features = None\n",
    "\n",
    "total_iterations = sum(1 for r in range(1, len(selected_feature_list) + 1) for _ in itertools.combinations(selected_feature_list, r))\n",
    "current_iteration = 0\n",
    "\n",
    "# Loop over all possible subsets of the 10 selected features\n",
    "for r in range(1, len(selected_feature_list) + 1):\n",
    "    for subset in itertools.combinations(selected_feature_list, r):\n",
    "        current_iteration += 1\n",
    "        print(f\"Iteration {current_iteration}/{total_iterations}: Testing features {subset}\")\n",
    "        \n",
    "        varying_features = list(subset)\n",
    "        X = df[fixed_features + varying_features]  # Keep the 26 fixed features\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        \n",
    "        # Train XGB Regressor\n",
    "        model = XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print(f\"RMSE: {rmse}\\n\")\n",
    "        \n",
    "        # Check if this is the best RMSE so far\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_features = varying_features\n",
    "\n",
    "print(f\"Best RMSE: {best_rmse}\")\n",
    "print(f\"Best Feature Set: {best_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d44e8281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c5d0e1f940>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_predict)\n",
    "plt.plot([0,4], [0,4],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba678d54",
   "metadata": {},
   "source": [
    "df_pred = pd.read_csv('Carbon_binding_predictions_Cu_and_Ni_based_bimetallics_A3B_AA.csv')\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90def9",
   "metadata": {},
   "source": [
    "x = df_pred.drop(labels=[\"Element\",\"Carbon_B.E\",\"M-Enth.atom\",\"M-Enth.vap\",\"Enth.atom\",\"Enth.vap\"], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9514f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA_df_Cu_pred = pd.read_csv('PCA_add_Cu_Pred.csv')\n",
    "#PCA_df_Cu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca6601ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combined_df_Cu_pred = pd.concat([x, PCA_df_Cu_pred], axis=1)\n",
    "#df_Cu_pred = combined_df_Cu_pred\n",
    "#df_Cu_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da561d4",
   "metadata": {},
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50120201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_params = model.get_params()\n",
    "H_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea6e6e",
   "metadata": {},
   "source": [
    "p = model.predict(x)\n",
    "p = pd.DataFrame(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc548d",
   "metadata": {},
   "source": [
    "output_file_CO = 'output_data_CO.xlsx'\n",
    "p.to_excel(output_file_CO, index=False)\n",
    "print(f\"Data frame converted and saved to '{output_file_CO}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7405770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.3261537e-03 9.9949157e-03 3.5844103e-03 1.4889003e-01 1.4648801e-03\n",
      " 1.7293135e-03 2.9158718e-03 4.7385377e-01 1.6896619e-03 1.5962398e-02\n",
      " 3.0763154e-03 4.9409962e-05 2.3381938e-03 1.1867752e-02 3.5682968e-03\n",
      " 1.3261316e-03 8.9530580e-02 1.7170468e-02 1.2073067e-01 8.4461058e-03\n",
      " 3.8539898e-03 1.2671479e-02 3.4790773e-02 1.9597847e-02 5.5706115e-03]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe09779",
   "metadata": {},
   "source": [
    "!pip install scikit-learn==1.3.0\n",
    "!pip install xgboost==1.7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab02332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.stats.qmc import Sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85fed8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "params = { 'max_depth': np.arange(10,15,1),                     #13\n",
    "           'learning_rate': np.arange(0.01,0.03, 0.005),      #0.325\n",
    "           #'subsample': np.arange(0.7, 1, 0.01), \n",
    "           'min_child_weight': np.arange(8,12, 1),\n",
    "           #'colsample_bytree': np.arange(0.99, 1, 0.01),        \n",
    "           #'colsample_bylevel': np.arange(0.99, 1, 0.01),       \n",
    "           'n_estimators': np.arange(600,1000,25),                #450\n",
    "           #'reg_alpha': uniform(1,3),                     #0.8612124738904751\n",
    "           #'reg_lambda': uniform(1,10),                 #115.01455430429743  \n",
    "         }\n",
    "sobol_sequence = Sobol(1)\n",
    "lasso = Lasso()\n",
    "# number of times random search is run\n",
    "n = 50                                             # n=20    #n_iter=50  #cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc630665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 1: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=850, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 1th run - Training: 0.055663824111231296, Test: 0.4274422822072839\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 2: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=950, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 2th run - Training: 0.04616394042520723, Test: 0.42350750297082496\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 3: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=875, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 3th run - Training: 0.07337341469403373, Test: 0.41339744899308634\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 4: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 4th run - Training: 0.08353825903769697, Test: 0.41385130610897564\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 5: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=800, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 5th run - Training: 0.05923391378048832, Test: 0.4247545889576771\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 6: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=850, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 6th run - Training: 0.055663824111231296, Test: 0.4274422822072839\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 7: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 7th run - Training: 0.0723682597962587, Test: 0.42959087610366375\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 8: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=875, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 8th run - Training: 0.052224522168551425, Test: 0.4239569161852302\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 9: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 9th run - Training: 0.06355619306888831, Test: 0.42938680850016764\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=850, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 10th run - Training: 0.05433636527811815, Test: 0.4242358323136875\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 11: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=875, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 11th run - Training: 0.05320459027196056, Test: 0.4263946033497847\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 12: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=975, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 12th run - Training: 0.0453113963248301, Test: 0.42511284346017153\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 13: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=925, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 13th run - Training: 0.048115004299152685, Test: 0.42346826290043427\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 14: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 14th run - Training: 0.05083862941412025, Test: 0.42553566269734394\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 15: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 15th run - Training: 0.07112356818282901, Test: 0.41315803834219805\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 16: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=650, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 16th run - Training: 0.10084737234578903, Test: 0.4183919888167603\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 17: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 17th run - Training: 0.06355619306888831, Test: 0.42938680850016764\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 18: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 18th run - Training: 0.06355619306888831, Test: 0.42938680850016764\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 19: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 19th run - Training: 0.07145806477496135, Test: 0.41910338054557933\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 20: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 20th run - Training: 0.0691246681141903, Test: 0.42935767278110043\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 21: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=650, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 21th run - Training: 0.07884114971268683, Test: 0.4276321027324495\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 22: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 22th run - Training: 0.05083862941412025, Test: 0.42553566269734394\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 23: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 23th run - Training: 0.0691246681141903, Test: 0.42935767278110043\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 24: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=925, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 24th run - Training: 0.048758122538183936, Test: 0.4254085606284499\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 25: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=925, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 25th run - Training: 0.048115004299152685, Test: 0.42346826290043427\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 26: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=875, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 26th run - Training: 0.05320459027196056, Test: 0.4263946033497847\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 27: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 27th run - Training: 0.05082930769526872, Test: 0.4255729655445227\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 28: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 28th run - Training: 0.06815624695820832, Test: 0.42527074133054954\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 29: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=750, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 29th run - Training: 0.06628478660702135, Test: 0.42993512491762564\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 30: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=675, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 30th run - Training: 0.07513921866092545, Test: 0.4268727599337479\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 31: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 31th run - Training: 0.08392634277059519, Test: 0.4154212124783969\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 32: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=975, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 32th run - Training: 0.0453113963248301, Test: 0.42511284346017153\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 33: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 33th run - Training: 0.05082930769526872, Test: 0.4255729655445227\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 34: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=875, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 34th run - Training: 0.07337341469403373, Test: 0.41339744899308634\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 35: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 35th run - Training: 0.05083862941412025, Test: 0.42553566269734394\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 36: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 36th run - Training: 0.08969081372280922, Test: 0.41479333183870504\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 37: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=600, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 37th run - Training: 0.0867237135299889, Test: 0.4309062473939612\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 38: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 38th run - Training: 0.0691246681141903, Test: 0.42935767278110043\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 39: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 39th run - Training: 0.05082930769526872, Test: 0.4255729655445227\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 40: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=625, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 40th run - Training: 0.08261418703485549, Test: 0.4300817327295889\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 41: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 41th run - Training: 0.06281418590364089, Test: 0.4298030099997002\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 42: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=825, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 42th run - Training: 0.05762482962997586, Test: 0.42920356610018134\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 43: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 43th run - Training: 0.05082930769526872, Test: 0.4255729655445227\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 44: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 44th run - Training: 0.08969081372280922, Test: 0.41479333183870504\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 45: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 45th run - Training: 0.05082930769526872, Test: 0.4255729655445227\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 46: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=800, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 46th run - Training: 0.06010548986895953, Test: 0.42940321669506193\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 47: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 47th run - Training: 0.06355619306888831, Test: 0.42938680850016764\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 48: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 48th run - Training: 0.0691246681141903, Test: 0.42935767278110043\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 49: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.024999999999999998,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=800, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 49th run - Training: 0.06067281048005118, Test: 0.42850173704225836\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 50: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.019999999999999997,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=875, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 50th run - Training: 0.0732124541827019, Test: 0.4131372357594616\n"
     ]
    }
   ],
   "source": [
    "xgbr = xgb.XGBRegressor(seed=20)\n",
    "average = np.array([0]*25, dtype=np.float64)\n",
    "feature_importances = []\n",
    "\n",
    "nth_run = 1\n",
    "rmse_values_test = []\n",
    "rmse_values_train = []\n",
    "avg = 0\n",
    "\n",
    "for i in range(n):   \n",
    "    clf = RandomizedSearchCV(estimator=xgbr,\n",
    "                             param_distributions=params,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             n_iter=30,cv=10,random_state=np.random.RandomState(int(sobol_sequence.random(1)[0] * 2**31)),\n",
    "                             verbose=1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    print(f\"Run {i + 1}: Best Estimator: {clf.best_estimator_}\")\n",
    "    \n",
    "    if (i + 1) % nth_run == 0:\n",
    "        # Predictions on test set\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        rmse_values_test.append(rmse_test)\n",
    "        \n",
    "        # Predictions on training set\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        rmse_values_train.append(rmse_train)\n",
    "\n",
    "        print(f\"RMSE for every {nth_run}th run - Training: {rmse_train}, Test: {rmse_test}\")\n",
    "        nth_run += 1\n",
    "    \n",
    "    average += clf.best_estimator_.feature_importances_\n",
    "    feature_importances.append(clf.best_estimator_.feature_importances_)\n",
    "average = average/n\n",
    "avg = avg/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d574c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b42d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4131372357594616, 0.4309062473939612)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(rmse_values_test), np.max(rmse_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a3ec9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0453113963248301, 0.10084737234578903)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(rmse_values_train), np.max(rmse_values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b14d20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 0.4246558992904936\n"
     ]
    }
   ],
   "source": [
    "mean_rmse_test = np.mean(rmse_values_test)\n",
    "print(f\"Mean RMSE: {mean_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f13f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 0.06368543523933498\n"
     ]
    }
   ],
   "source": [
    "mean_rmse_train = np.mean(rmse_values_train)\n",
    "print(f\"Mean RMSE: {mean_rmse_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bffb36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1c5d33fde20>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d33fd880>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d31d3ac0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d34541c0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3454910>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d345a0a0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d345a7f0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d345d0a0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d345d6d0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d345aa90>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d34546a0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d345dd00>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3467490>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3467be0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d346b370>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d346bac0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3467700>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d345dfd0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d346b700>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3473370>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3473ac0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3477250>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3473eb0>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d346b130>,\n",
       "  <matplotlib.axis.XTick at 0x1c5d3477af0>],\n",
       " [Text(0, 0, 'M-At wt.'),\n",
       "  Text(1, 0, 'M-M.P'),\n",
       "  Text(2, 0, 'M-B.P'),\n",
       "  Text(3, 0, 'M-Enth.fus'),\n",
       "  Text(4, 0, 'M-Enth.vap'),\n",
       "  Text(5, 0, 'M-Sp.ht Cap'),\n",
       "  Text(6, 0, 'M-Elec.-ve'),\n",
       "  Text(7, 0, 'M-Surface.E'),\n",
       "  Text(8, 0, 'M-1st Ion E'),\n",
       "  Text(9, 0, 'M-cova .radii'),\n",
       "  Text(10, 0, 'M-At.radii'),\n",
       "  Text(11, 0, 'M-Group'),\n",
       "  Text(12, 0, 'Density'),\n",
       "  Text(13, 0, 'M.P'),\n",
       "  Text(14, 0, 'B.P'),\n",
       "  Text(15, 0, 'Enth.fus'),\n",
       "  Text(16, 0, 'Enth.atom'),\n",
       "  Text(17, 0, 'Elec.-ve'),\n",
       "  Text(18, 0, 'Surface.E'),\n",
       "  Text(19, 0, '1st Ion E'),\n",
       "  Text(20, 0, 'cova .radii'),\n",
       "  Text(21, 0, 'At.radii'),\n",
       "  Text(22, 0, 'Group'),\n",
       "  Text(23, 0, 'Work F.'),\n",
       "  Text(24, 0, 'Elec.Aff')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=range(25), height=np.mean(feature_importances, axis=0), yerr=np.std(feature_importances, axis=0))\n",
    "plt.xticks(ticks = range(25),labels=X_train.columns, rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "945911e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg-MSE: -0.23119309693282805\n"
     ]
    }
   ],
   "source": [
    "print(\"neg-MSE:\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "354d34a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4131372357594616"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.best_estimator_.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "rmse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6820b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a1027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
