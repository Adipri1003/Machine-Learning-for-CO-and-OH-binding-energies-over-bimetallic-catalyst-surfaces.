{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b91116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cfece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b1bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>...</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "      <th>CO_B.E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ag3M-Ti</td>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.93</td>\n",
       "      <td>658.80</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.33</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.110488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ag3M-V</td>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.38</td>\n",
       "      <td>650.90</td>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.30</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0.041306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ag3M-Cr</td>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.22</td>\n",
       "      <td>652.90</td>\n",
       "      <td>139</td>\n",
       "      <td>166</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>64.3</td>\n",
       "      <td>0.032003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ag3M-Mn</td>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.39</td>\n",
       "      <td>717.30</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.034649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ag3M-Co</td>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.11</td>\n",
       "      <td>760.40</td>\n",
       "      <td>126</td>\n",
       "      <td>152</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.00</td>\n",
       "      <td>63.7</td>\n",
       "      <td>0.037391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Ir3M-Re</td>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.57</td>\n",
       "      <td>760.00</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.72</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-1.447916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Ir3M-Os</td>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.00</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.93</td>\n",
       "      <td>106.1</td>\n",
       "      <td>-1.608018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Ir3M-Pt</td>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.00</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.97</td>\n",
       "      <td>205.3</td>\n",
       "      <td>-1.956184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Ir3M-Au</td>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>136</td>\n",
       "      <td>174</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.41</td>\n",
       "      <td>222.8</td>\n",
       "      <td>-1.998453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Ir3M-Bi</td>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>703.00</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.34</td>\n",
       "      <td>91.2</td>\n",
       "      <td>-1.794044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Element  M-At No.  M-At wt.  M-Density    M-M.P  M-B.P  M-Enth.fus  \\\n",
       "0    Ag3M-Ti        47    107.87      10.49  1234.93   2435        11.3   \n",
       "1     Ag3M-V        47    107.87      10.49  1234.93   2435        11.3   \n",
       "2    Ag3M-Cr        47    107.87      10.49  1234.93   2435        11.3   \n",
       "3    Ag3M-Mn        47    107.87      10.49  1234.93   2435        11.3   \n",
       "4    Ag3M-Co        47    107.87      10.49  1234.93   2435        11.3   \n",
       "..       ...       ...       ...        ...      ...    ...         ...   \n",
       "151  Ir3M-Re        77    192.22      22.56  2739.00   4701        26.0   \n",
       "152  Ir3M-Os        77    192.22      22.56  2739.00   4701        26.0   \n",
       "153  Ir3M-Pt        77    192.22      22.56  2739.00   4701        26.0   \n",
       "154  Ir3M-Au        77    192.22      22.56  2739.00   4701        26.0   \n",
       "155  Ir3M-Bi        77    192.22      22.56  2739.00   4701        26.0   \n",
       "\n",
       "     M-Enth.atom  M-Enth.vap  M-Sp.ht Cap  ...  Elec.-ve  Surface.E  \\\n",
       "0            285         255          235  ...      1.54       1.93   \n",
       "1            285         255          235  ...      1.63       2.38   \n",
       "2            285         255          235  ...      1.66       3.22   \n",
       "3            285         255          235  ...      1.55       3.39   \n",
       "4            285         255          235  ...      1.88       2.11   \n",
       "..           ...         ...          ...  ...       ...        ...   \n",
       "151          671         560          131  ...      1.90       2.57   \n",
       "152          671         560          131  ...      2.20       2.95   \n",
       "153          671         560          131  ...      2.28       1.49   \n",
       "154          671         560          131  ...      2.54       0.74   \n",
       "155          671         560          131  ...      2.02       0.17   \n",
       "\n",
       "     1st Ion E  cova .radii  At.radii  Group  Period  Work F.  Elec.Aff  \\\n",
       "0       658.80          160       176    4.0       4     4.33       7.6   \n",
       "1       650.90          153       171    5.0       4     4.30      50.6   \n",
       "2       652.90          139       166    6.0       4     4.50      64.3   \n",
       "3       717.30          139       161    7.0       4     4.10     -50.0   \n",
       "4       760.40          126       152    9.0       4     5.00      63.7   \n",
       "..         ...          ...       ...    ...     ...      ...       ...   \n",
       "151     760.00          159       188    7.0       6     4.72      14.5   \n",
       "152     840.00          128       185    8.0       6     5.93     106.1   \n",
       "153     870.00          136       177   10.0       6     5.97     205.3   \n",
       "154     890.13          136       174   11.0       6     5.41     222.8   \n",
       "155     703.00          148       143   15.0       6     4.34      91.2   \n",
       "\n",
       "       CO_B.E  \n",
       "0    0.110488  \n",
       "1    0.041306  \n",
       "2    0.032003  \n",
       "3    0.034649  \n",
       "4    0.037391  \n",
       "..        ...  \n",
       "151 -1.447916  \n",
       "152 -1.608018  \n",
       "153 -1.956184  \n",
       "154 -1.998453  \n",
       "155 -1.794044  \n",
       "\n",
       "[156 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('DATASET_A3B_CO-without_Cu.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa8af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CO_B.E'] = df['CO_B.E'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900236db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>...</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "      <th>CO_B.E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.93</td>\n",
       "      <td>658.80</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.33</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.110488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.38</td>\n",
       "      <td>650.90</td>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.30</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0.041306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.22</td>\n",
       "      <td>652.90</td>\n",
       "      <td>139</td>\n",
       "      <td>166</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>64.3</td>\n",
       "      <td>0.032003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.39</td>\n",
       "      <td>717.30</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.034649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>11.3</td>\n",
       "      <td>285</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.11</td>\n",
       "      <td>760.40</td>\n",
       "      <td>126</td>\n",
       "      <td>152</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.00</td>\n",
       "      <td>63.7</td>\n",
       "      <td>0.037391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.57</td>\n",
       "      <td>760.00</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.72</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-1.447916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.00</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.93</td>\n",
       "      <td>106.1</td>\n",
       "      <td>-1.608018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.00</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.97</td>\n",
       "      <td>205.3</td>\n",
       "      <td>-1.956184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>136</td>\n",
       "      <td>174</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.41</td>\n",
       "      <td>222.8</td>\n",
       "      <td>-1.998453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>26.0</td>\n",
       "      <td>671</td>\n",
       "      <td>560</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>703.00</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.34</td>\n",
       "      <td>91.2</td>\n",
       "      <td>-1.794044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     M-At No.  M-At wt.  M-Density    M-M.P  M-B.P  M-Enth.fus  M-Enth.atom  \\\n",
       "0          47    107.87      10.49  1234.93   2435        11.3          285   \n",
       "1          47    107.87      10.49  1234.93   2435        11.3          285   \n",
       "2          47    107.87      10.49  1234.93   2435        11.3          285   \n",
       "3          47    107.87      10.49  1234.93   2435        11.3          285   \n",
       "4          47    107.87      10.49  1234.93   2435        11.3          285   \n",
       "..        ...       ...        ...      ...    ...         ...          ...   \n",
       "151        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "152        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "153        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "154        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "155        77    192.22      22.56  2739.00   4701        26.0          671   \n",
       "\n",
       "     M-Enth.vap  M-Sp.ht Cap  M-Elec.-ve  ...  Elec.-ve  Surface.E  1st Ion E  \\\n",
       "0           255          235        1.93  ...      1.54       1.93     658.80   \n",
       "1           255          235        1.93  ...      1.63       2.38     650.90   \n",
       "2           255          235        1.93  ...      1.66       3.22     652.90   \n",
       "3           255          235        1.93  ...      1.55       3.39     717.30   \n",
       "4           255          235        1.93  ...      1.88       2.11     760.40   \n",
       "..          ...          ...         ...  ...       ...        ...        ...   \n",
       "151         560          131        2.20  ...      1.90       2.57     760.00   \n",
       "152         560          131        2.20  ...      2.20       2.95     840.00   \n",
       "153         560          131        2.20  ...      2.28       1.49     870.00   \n",
       "154         560          131        2.20  ...      2.54       0.74     890.13   \n",
       "155         560          131        2.20  ...      2.02       0.17     703.00   \n",
       "\n",
       "     cova .radii  At.radii  Group  Period  Work F.  Elec.Aff    CO_B.E  \n",
       "0            160       176    4.0       4     4.33       7.6  0.110488  \n",
       "1            153       171    5.0       4     4.30      50.6  0.041306  \n",
       "2            139       166    6.0       4     4.50      64.3  0.032003  \n",
       "3            139       161    7.0       4     4.10     -50.0  0.034649  \n",
       "4            126       152    9.0       4     5.00      63.7  0.037391  \n",
       "..           ...       ...    ...     ...      ...       ...       ...  \n",
       "151          159       188    7.0       6     4.72      14.5 -1.447916  \n",
       "152          128       185    8.0       6     5.93     106.1 -1.608018  \n",
       "153          136       177   10.0       6     5.97     205.3 -1.956184  \n",
       "154          136       174   11.0       6     5.41     222.8 -1.998453  \n",
       "155          148       143   15.0       6     4.34      91.2 -1.794044  \n",
       "\n",
       "[156 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.iloc[:,1:38]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc4165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M-At No.', 'M-At wt.', 'M-Density', 'M-M.P', 'M-B.P', 'M-Enth.fus', 'M-Enth.atom', 'M-Enth.vap', 'M-Sp.ht Cap', 'M-Elec.-ve', 'M-Surface.E', 'M-1st Ion E', 'M-cova .radii', 'M-At.radii', 'M-Group', 'M-Period', 'M-Work F.', 'M-Elec.Aff', 'At No.', 'At wt.', 'Density', 'M.P', 'B.P', 'Enth.fus', 'Enth.atom', 'Enth.vap', 'Sp.ht Cap', 'Elec.-ve', 'Surface.E', '1st Ion E', 'cova .radii', 'At.radii', 'Group', 'Period', 'Work F.', 'Elec.Aff', 'CO_B.E']\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d45ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df2\n",
    "y= df['CO_B.E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d9d8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109, 37), (47, 37))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d7f73",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "cor = df2.corr()\n",
    "G=sns.heatmap(cor,annot=True,cmap=\"RdYlBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9dc1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>M-Surface.E</th>\n",
       "      <th>M-1st Ion E</th>\n",
       "      <th>M-cova .radii</th>\n",
       "      <th>...</th>\n",
       "      <th>Sp.ht Cap</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.170</td>\n",
       "      <td>731.0</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.93</td>\n",
       "      <td>658.80</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.33</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.170</td>\n",
       "      <td>731.0</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>489.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.38</td>\n",
       "      <td>650.90</td>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.30</td>\n",
       "      <td>50.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.170</td>\n",
       "      <td>731.0</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.22</td>\n",
       "      <td>652.90</td>\n",
       "      <td>139</td>\n",
       "      <td>166</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>64.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.170</td>\n",
       "      <td>731.0</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.39</td>\n",
       "      <td>717.30</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>107.87</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1234.93</td>\n",
       "      <td>2435</td>\n",
       "      <td>235</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.170</td>\n",
       "      <td>731.0</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.11</td>\n",
       "      <td>760.40</td>\n",
       "      <td>126</td>\n",
       "      <td>152</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.00</td>\n",
       "      <td>63.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.971</td>\n",
       "      <td>880.0</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.57</td>\n",
       "      <td>760.00</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.72</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.971</td>\n",
       "      <td>880.0</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.00</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.93</td>\n",
       "      <td>106.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.971</td>\n",
       "      <td>880.0</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.00</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.97</td>\n",
       "      <td>205.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.971</td>\n",
       "      <td>880.0</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>136</td>\n",
       "      <td>174</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.41</td>\n",
       "      <td>222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>77</td>\n",
       "      <td>192.22</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2739.00</td>\n",
       "      <td>4701</td>\n",
       "      <td>131</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.971</td>\n",
       "      <td>880.0</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>703.00</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.34</td>\n",
       "      <td>91.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     M-At No.  M-At wt.  M-Density    M-M.P  M-B.P  M-Sp.ht Cap  M-Elec.-ve  \\\n",
       "0          47    107.87      10.49  1234.93   2435          235        1.93   \n",
       "1          47    107.87      10.49  1234.93   2435          235        1.93   \n",
       "2          47    107.87      10.49  1234.93   2435          235        1.93   \n",
       "3          47    107.87      10.49  1234.93   2435          235        1.93   \n",
       "4          47    107.87      10.49  1234.93   2435          235        1.93   \n",
       "..        ...       ...        ...      ...    ...          ...         ...   \n",
       "151        77    192.22      22.56  2739.00   4701          131        2.20   \n",
       "152        77    192.22      22.56  2739.00   4701          131        2.20   \n",
       "153        77    192.22      22.56  2739.00   4701          131        2.20   \n",
       "154        77    192.22      22.56  2739.00   4701          131        2.20   \n",
       "155        77    192.22      22.56  2739.00   4701          131        2.20   \n",
       "\n",
       "     M-Surface.E  M-1st Ion E  M-cova .radii  ...  Sp.ht Cap  Elec.-ve  \\\n",
       "0          1.170        731.0            145  ...      520.0      1.54   \n",
       "1          1.170        731.0            145  ...      489.0      1.63   \n",
       "2          1.170        731.0            145  ...      448.0      1.66   \n",
       "3          1.170        731.0            145  ...      479.0      1.55   \n",
       "4          1.170        731.0            145  ...      421.0      1.88   \n",
       "..           ...          ...            ...  ...        ...       ...   \n",
       "151        2.971        880.0            137  ...      137.0      1.90   \n",
       "152        2.971        880.0            137  ...      130.0      2.20   \n",
       "153        2.971        880.0            137  ...      133.0      2.28   \n",
       "154        2.971        880.0            137  ...      129.1      2.54   \n",
       "155        2.971        880.0            137  ...      122.0      2.02   \n",
       "\n",
       "     Surface.E  1st Ion E  cova .radii  At.radii  Group  Period  Work F.  \\\n",
       "0         1.93     658.80          160       176    4.0       4     4.33   \n",
       "1         2.38     650.90          153       171    5.0       4     4.30   \n",
       "2         3.22     652.90          139       166    6.0       4     4.50   \n",
       "3         3.39     717.30          139       161    7.0       4     4.10   \n",
       "4         2.11     760.40          126       152    9.0       4     5.00   \n",
       "..         ...        ...          ...       ...    ...     ...      ...   \n",
       "151       2.57     760.00          159       188    7.0       6     4.72   \n",
       "152       2.95     840.00          128       185    8.0       6     5.93   \n",
       "153       1.49     870.00          136       177   10.0       6     5.97   \n",
       "154       0.74     890.13          136       174   11.0       6     5.41   \n",
       "155       0.17     703.00          148       143   15.0       6     4.34   \n",
       "\n",
       "     Elec.Aff  \n",
       "0         7.6  \n",
       "1        50.6  \n",
       "2        64.3  \n",
       "3       -50.0  \n",
       "4        63.7  \n",
       "..        ...  \n",
       "151      14.5  \n",
       "152     106.1  \n",
       "153     205.3  \n",
       "154     222.8  \n",
       "155      91.2  \n",
       "\n",
       "[156 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.drop(labels=[\"CO_B.E\",\"M-Enth.fus\", \"M-Enth.vap\",\"Enth.fus\",\"Enth.vap\",\"M-Enth.atom\",\"Enth.atom\"], axis=1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42fbcd",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "cor = df3.corr()\n",
    "G=sns.heatmap(cor,annot=True,cmap=\"RdYlBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f3a9b",
   "metadata": {},
   "source": [
    "PCA_df = pd.read_csv('PCA_add.csv')\n",
    "PCA_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca65961",
   "metadata": {},
   "source": [
    "combined_df = pd.concat([df3, PCA_df], axis=1)\n",
    "df4 = combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a30606",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57467076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.figure(figsize=(25,25))\n",
    "#cor = df4.corr()\n",
    "#G=sns.heatmap(cor,annot=True,cmap=\"RdYlBu\")\n",
    "#lt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba48fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3\n",
    "y = df['CO_B.E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8183bc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109, 30), (47, 30))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9289beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on test data is 0.9702947106763663\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "print(\"r2 on test data is\",   r2_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b6839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:0.08200909405694341\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\"+str(np.sqrt(mean_squared_error(y_test, y_predict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d44e8281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26692c1ac70>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_predict)\n",
    "plt.plot([-2.5,0.5], [-2.5,0.5],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476ea20c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Enth.fus</th>\n",
       "      <th>M-Enth.atom</th>\n",
       "      <th>M-Enth.vap</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>...</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "      <th>CO_B.E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cu3M-Sc</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.20</td>\n",
       "      <td>633.10</td>\n",
       "      <td>170</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.500</td>\n",
       "      <td>18.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cu3M-Ti</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.93</td>\n",
       "      <td>658.80</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.330</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cu3M-V</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.38</td>\n",
       "      <td>650.90</td>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4.300</td>\n",
       "      <td>50.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cu3M-Cr</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.22</td>\n",
       "      <td>652.90</td>\n",
       "      <td>139</td>\n",
       "      <td>166</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.500</td>\n",
       "      <td>64.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cu3M-Mn</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.39</td>\n",
       "      <td>717.30</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.100</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cu3M-Co</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.11</td>\n",
       "      <td>760.40</td>\n",
       "      <td>126</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000</td>\n",
       "      <td>63.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cu3M-Ni</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>737.10</td>\n",
       "      <td>121</td>\n",
       "      <td>149</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5.240</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cu3M-Zn</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.33</td>\n",
       "      <td>906.40</td>\n",
       "      <td>122</td>\n",
       "      <td>142</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3.630</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cu3M-Ga</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.48</td>\n",
       "      <td>578.80</td>\n",
       "      <td>122</td>\n",
       "      <td>136</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4.320</td>\n",
       "      <td>28.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cu3M-Y</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>600.00</td>\n",
       "      <td>190</td>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.183</td>\n",
       "      <td>29.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cu3M-Zr</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.60</td>\n",
       "      <td>640.10</td>\n",
       "      <td>175</td>\n",
       "      <td>206</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.050</td>\n",
       "      <td>41.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cu3M-Nb</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.06</td>\n",
       "      <td>652.10</td>\n",
       "      <td>164</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.360</td>\n",
       "      <td>86.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cu3M-Mo</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.78</td>\n",
       "      <td>684.30</td>\n",
       "      <td>154</td>\n",
       "      <td>190</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4.520</td>\n",
       "      <td>71.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cu3M-Ru</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>710.20</td>\n",
       "      <td>126</td>\n",
       "      <td>178</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4.650</td>\n",
       "      <td>101.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cu3M-Rh</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.98</td>\n",
       "      <td>719.70</td>\n",
       "      <td>135</td>\n",
       "      <td>173</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5.200</td>\n",
       "      <td>109.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cu3M-Pd</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>804.40</td>\n",
       "      <td>131</td>\n",
       "      <td>169</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.470</td>\n",
       "      <td>53.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cu3M-Ag</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>731.00</td>\n",
       "      <td>145</td>\n",
       "      <td>165</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4.630</td>\n",
       "      <td>125.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cu3M-Sn</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.54</td>\n",
       "      <td>708.60</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>4.420</td>\n",
       "      <td>107.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cu3M-Ta</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.34</td>\n",
       "      <td>761.00</td>\n",
       "      <td>170</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cu3M-Re</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.57</td>\n",
       "      <td>760.00</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4.720</td>\n",
       "      <td>14.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cu3M-Os</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.00</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5.930</td>\n",
       "      <td>106.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cu3M-Ir</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>137</td>\n",
       "      <td>180</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5.760</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cu3M-Pt</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.00</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5.970</td>\n",
       "      <td>205.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cu3M-Au</td>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>13.1</td>\n",
       "      <td>338</td>\n",
       "      <td>300</td>\n",
       "      <td>384.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>136</td>\n",
       "      <td>174</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5.410</td>\n",
       "      <td>222.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Element  M-At No.  M-At wt.  M-Density  M-M.P  M-B.P  M-Enth.fus  \\\n",
       "0   Cu3M-Sc        29    63.546       8.96   1357   2835        13.1   \n",
       "1   Cu3M-Ti        29    63.546       8.96   1357   2835        13.1   \n",
       "2    Cu3M-V        29    63.546       8.96   1357   2835        13.1   \n",
       "3   Cu3M-Cr        29    63.546       8.96   1357   2835        13.1   \n",
       "4   Cu3M-Mn        29    63.546       8.96   1357   2835        13.1   \n",
       "5   Cu3M-Co        29    63.546       8.96   1357   2835        13.1   \n",
       "6   Cu3M-Ni        29    63.546       8.96   1357   2835        13.1   \n",
       "7   Cu3M-Zn        29    63.546       8.96   1357   2835        13.1   \n",
       "8   Cu3M-Ga        29    63.546       8.96   1357   2835        13.1   \n",
       "9    Cu3M-Y        29    63.546       8.96   1357   2835        13.1   \n",
       "10  Cu3M-Zr        29    63.546       8.96   1357   2835        13.1   \n",
       "11  Cu3M-Nb        29    63.546       8.96   1357   2835        13.1   \n",
       "12  Cu3M-Mo        29    63.546       8.96   1357   2835        13.1   \n",
       "13  Cu3M-Ru        29    63.546       8.96   1357   2835        13.1   \n",
       "14  Cu3M-Rh        29    63.546       8.96   1357   2835        13.1   \n",
       "15  Cu3M-Pd        29    63.546       8.96   1357   2835        13.1   \n",
       "16  Cu3M-Ag        29    63.546       8.96   1357   2835        13.1   \n",
       "17  Cu3M-Sn        29    63.546       8.96   1357   2835        13.1   \n",
       "18  Cu3M-Ta        29    63.546       8.96   1357   2835        13.1   \n",
       "19  Cu3M-Re        29    63.546       8.96   1357   2835        13.1   \n",
       "20  Cu3M-Os        29    63.546       8.96   1357   2835        13.1   \n",
       "21  Cu3M-Ir        29    63.546       8.96   1357   2835        13.1   \n",
       "22  Cu3M-Pt        29    63.546       8.96   1357   2835        13.1   \n",
       "23  Cu3M-Au        29    63.546       8.96   1357   2835        13.1   \n",
       "\n",
       "    M-Enth.atom  M-Enth.vap  M-Sp.ht Cap  ...  Elec.-ve  Surface.E  1st Ion E  \\\n",
       "0           338         300        384.4  ...      1.36       1.20     633.10   \n",
       "1           338         300        384.4  ...      1.54       1.93     658.80   \n",
       "2           338         300        384.4  ...      1.63       2.38     650.90   \n",
       "3           338         300        384.4  ...      1.66       3.22     652.90   \n",
       "4           338         300        384.4  ...      1.55       3.39     717.30   \n",
       "5           338         300        384.4  ...      1.88       2.11     760.40   \n",
       "6           338         300        384.4  ...      1.91       1.92     737.10   \n",
       "7           338         300        384.4  ...      1.65       0.33     906.40   \n",
       "8           338         300        384.4  ...      1.81       0.48     578.80   \n",
       "9           338         300        384.4  ...      1.22       1.00     600.00   \n",
       "10          338         300        384.4  ...      1.33       1.60     640.10   \n",
       "11          338         300        384.4  ...      1.60       2.06     652.10   \n",
       "12          338         300        384.4  ...      2.16       2.78     684.30   \n",
       "13          338         300        384.4  ...      2.20       2.60     710.20   \n",
       "14          338         300        384.4  ...      2.28       1.98     719.70   \n",
       "15          338         300        384.4  ...      2.20       1.36     804.40   \n",
       "16          338         300        384.4  ...      1.93       0.76     731.00   \n",
       "17          338         300        384.4  ...      1.96       0.54     708.60   \n",
       "18          338         300        384.4  ...      1.50       2.34     761.00   \n",
       "19          338         300        384.4  ...      1.90       2.57     760.00   \n",
       "20          338         300        384.4  ...      2.20       2.95     840.00   \n",
       "21          338         300        384.4  ...      2.20       2.36     880.00   \n",
       "22          338         300        384.4  ...      2.28       1.49     870.00   \n",
       "23          338         300        384.4  ...      2.54       0.74     890.13   \n",
       "\n",
       "    cova .radii  At.radii  Group  Period  Work F.  Elec.Aff  CO_B.E  \n",
       "0           170       184      3       4    3.500      18.1     NaN  \n",
       "1           160       176      4       4    4.330       7.6     NaN  \n",
       "2           153       171      5       4    4.300      50.6     NaN  \n",
       "3           139       166      6       4    4.500      64.3     NaN  \n",
       "4           139       161      7       4    4.100     -50.0     NaN  \n",
       "5           126       152      9       4    5.000      63.7     NaN  \n",
       "6           121       149     10       4    5.240     112.0     NaN  \n",
       "7           122       142     12       4    3.630     -58.0     NaN  \n",
       "8           122       136     13       4    4.320      28.9     NaN  \n",
       "9           190       212      3       5    3.183      29.6     NaN  \n",
       "10          175       206      4       5    4.050      41.1     NaN  \n",
       "11          164       198      5       5    4.360      86.1     NaN  \n",
       "12          154       190      6       5    4.520      71.9     NaN  \n",
       "13          126       178      8       5    4.650     101.3     NaN  \n",
       "14          135       173      9       5    5.200     109.7     NaN  \n",
       "15          131       169     10       5    5.470      53.7     NaN  \n",
       "16          145       165     11       5    4.630     125.6     NaN  \n",
       "17          139       145     14       5    4.420     107.3     NaN  \n",
       "18          170       200      5       6    4.000      31.0     NaN  \n",
       "19          159       188      7       6    4.720      14.5     NaN  \n",
       "20          128       185      8       6    5.930     106.1     NaN  \n",
       "21          137       180      9       6    5.760     151.0     NaN  \n",
       "22          136       177     10       6    5.970     205.3     NaN  \n",
       "23          136       174     11       6    5.410     222.8     NaN  \n",
       "\n",
       "[24 rows x 38 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv('Cu_based_bimet_CO_Binding.csv')\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeec5090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-At No.</th>\n",
       "      <th>M-At wt.</th>\n",
       "      <th>M-Density</th>\n",
       "      <th>M-M.P</th>\n",
       "      <th>M-B.P</th>\n",
       "      <th>M-Sp.ht Cap</th>\n",
       "      <th>M-Elec.-ve</th>\n",
       "      <th>M-Surface.E</th>\n",
       "      <th>M-1st Ion E</th>\n",
       "      <th>M-cova .radii</th>\n",
       "      <th>...</th>\n",
       "      <th>Sp.ht Cap</th>\n",
       "      <th>Elec.-ve</th>\n",
       "      <th>Surface.E</th>\n",
       "      <th>1st Ion E</th>\n",
       "      <th>cova .radii</th>\n",
       "      <th>At.radii</th>\n",
       "      <th>Group</th>\n",
       "      <th>Period</th>\n",
       "      <th>Work F.</th>\n",
       "      <th>Elec.Aff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.20</td>\n",
       "      <td>633.10</td>\n",
       "      <td>170</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.500</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.93</td>\n",
       "      <td>658.80</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.330</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>489.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.38</td>\n",
       "      <td>650.90</td>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4.300</td>\n",
       "      <td>50.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.22</td>\n",
       "      <td>652.90</td>\n",
       "      <td>139</td>\n",
       "      <td>166</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.500</td>\n",
       "      <td>64.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.39</td>\n",
       "      <td>717.30</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.100</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.11</td>\n",
       "      <td>760.40</td>\n",
       "      <td>126</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000</td>\n",
       "      <td>63.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>445.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>737.10</td>\n",
       "      <td>121</td>\n",
       "      <td>149</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5.240</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>388.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.33</td>\n",
       "      <td>906.40</td>\n",
       "      <td>122</td>\n",
       "      <td>142</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3.630</td>\n",
       "      <td>-58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.48</td>\n",
       "      <td>578.80</td>\n",
       "      <td>122</td>\n",
       "      <td>136</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4.320</td>\n",
       "      <td>28.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>600.00</td>\n",
       "      <td>190</td>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.183</td>\n",
       "      <td>29.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.60</td>\n",
       "      <td>640.10</td>\n",
       "      <td>175</td>\n",
       "      <td>206</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.050</td>\n",
       "      <td>41.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.06</td>\n",
       "      <td>652.10</td>\n",
       "      <td>164</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.360</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>251.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.78</td>\n",
       "      <td>684.30</td>\n",
       "      <td>154</td>\n",
       "      <td>190</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4.520</td>\n",
       "      <td>71.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>710.20</td>\n",
       "      <td>126</td>\n",
       "      <td>178</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4.650</td>\n",
       "      <td>101.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.98</td>\n",
       "      <td>719.70</td>\n",
       "      <td>135</td>\n",
       "      <td>173</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5.200</td>\n",
       "      <td>109.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.36</td>\n",
       "      <td>804.40</td>\n",
       "      <td>131</td>\n",
       "      <td>169</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.470</td>\n",
       "      <td>53.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>731.00</td>\n",
       "      <td>145</td>\n",
       "      <td>165</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4.630</td>\n",
       "      <td>125.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.54</td>\n",
       "      <td>708.60</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>4.420</td>\n",
       "      <td>107.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.34</td>\n",
       "      <td>761.00</td>\n",
       "      <td>170</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.57</td>\n",
       "      <td>760.00</td>\n",
       "      <td>159</td>\n",
       "      <td>188</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4.720</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>840.00</td>\n",
       "      <td>128</td>\n",
       "      <td>185</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5.930</td>\n",
       "      <td>106.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.36</td>\n",
       "      <td>880.00</td>\n",
       "      <td>137</td>\n",
       "      <td>180</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5.760</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>870.00</td>\n",
       "      <td>136</td>\n",
       "      <td>177</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5.970</td>\n",
       "      <td>205.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29</td>\n",
       "      <td>63.546</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1357</td>\n",
       "      <td>2835</td>\n",
       "      <td>384.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.34</td>\n",
       "      <td>745.5</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>890.13</td>\n",
       "      <td>136</td>\n",
       "      <td>174</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5.410</td>\n",
       "      <td>222.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    M-At No.  M-At wt.  M-Density  M-M.P  M-B.P  M-Sp.ht Cap  M-Elec.-ve  \\\n",
       "0         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "1         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "2         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "3         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "4         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "5         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "6         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "7         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "8         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "9         29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "10        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "11        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "12        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "13        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "14        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "15        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "16        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "17        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "18        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "19        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "20        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "21        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "22        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "23        29    63.546       8.96   1357   2835        384.4         1.9   \n",
       "\n",
       "    M-Surface.E  M-1st Ion E  M-cova .radii  ...  Sp.ht Cap  Elec.-ve  \\\n",
       "0          1.34        745.5            132  ...      567.0      1.36   \n",
       "1          1.34        745.5            132  ...      520.0      1.54   \n",
       "2          1.34        745.5            132  ...      489.0      1.63   \n",
       "3          1.34        745.5            132  ...      448.0      1.66   \n",
       "4          1.34        745.5            132  ...      479.0      1.55   \n",
       "5          1.34        745.5            132  ...      421.0      1.88   \n",
       "6          1.34        745.5            132  ...      445.0      1.91   \n",
       "7          1.34        745.5            132  ...      388.0      1.65   \n",
       "8          1.34        745.5            132  ...      371.0      1.81   \n",
       "9          1.34        745.5            132  ...      298.0      1.22   \n",
       "10         1.34        745.5            132  ...      278.0      1.33   \n",
       "11         1.34        745.5            132  ...      265.0      1.60   \n",
       "12         1.34        745.5            132  ...      251.0      2.16   \n",
       "13         1.34        745.5            132  ...      238.0      2.20   \n",
       "14         1.34        745.5            132  ...      240.0      2.28   \n",
       "15         1.34        745.5            132  ...      240.0      2.20   \n",
       "16         1.34        745.5            132  ...      235.0      1.93   \n",
       "17         1.34        745.5            132  ...      217.0      1.96   \n",
       "18         1.34        745.5            132  ...      140.0      1.50   \n",
       "19         1.34        745.5            132  ...      137.0      1.90   \n",
       "20         1.34        745.5            132  ...      130.0      2.20   \n",
       "21         1.34        745.5            132  ...      131.0      2.20   \n",
       "22         1.34        745.5            132  ...      133.0      2.28   \n",
       "23         1.34        745.5            132  ...      129.1      2.54   \n",
       "\n",
       "    Surface.E  1st Ion E  cova .radii  At.radii  Group  Period  Work F.  \\\n",
       "0        1.20     633.10          170       184      3       4    3.500   \n",
       "1        1.93     658.80          160       176      4       4    4.330   \n",
       "2        2.38     650.90          153       171      5       4    4.300   \n",
       "3        3.22     652.90          139       166      6       4    4.500   \n",
       "4        3.39     717.30          139       161      7       4    4.100   \n",
       "5        2.11     760.40          126       152      9       4    5.000   \n",
       "6        1.92     737.10          121       149     10       4    5.240   \n",
       "7        0.33     906.40          122       142     12       4    3.630   \n",
       "8        0.48     578.80          122       136     13       4    4.320   \n",
       "9        1.00     600.00          190       212      3       5    3.183   \n",
       "10       1.60     640.10          175       206      4       5    4.050   \n",
       "11       2.06     652.10          164       198      5       5    4.360   \n",
       "12       2.78     684.30          154       190      6       5    4.520   \n",
       "13       2.60     710.20          126       178      8       5    4.650   \n",
       "14       1.98     719.70          135       173      9       5    5.200   \n",
       "15       1.36     804.40          131       169     10       5    5.470   \n",
       "16       0.76     731.00          145       165     11       5    4.630   \n",
       "17       0.54     708.60          139       145     14       5    4.420   \n",
       "18       2.34     761.00          170       200      5       6    4.000   \n",
       "19       2.57     760.00          159       188      7       6    4.720   \n",
       "20       2.95     840.00          128       185      8       6    5.930   \n",
       "21       2.36     880.00          137       180      9       6    5.760   \n",
       "22       1.49     870.00          136       177     10       6    5.970   \n",
       "23       0.74     890.13          136       174     11       6    5.410   \n",
       "\n",
       "    Elec.Aff  \n",
       "0       18.1  \n",
       "1        7.6  \n",
       "2       50.6  \n",
       "3       64.3  \n",
       "4      -50.0  \n",
       "5       63.7  \n",
       "6      112.0  \n",
       "7      -58.0  \n",
       "8       28.9  \n",
       "9       29.6  \n",
       "10      41.1  \n",
       "11      86.1  \n",
       "12      71.9  \n",
       "13     101.3  \n",
       "14     109.7  \n",
       "15      53.7  \n",
       "16     125.6  \n",
       "17     107.3  \n",
       "18      31.0  \n",
       "19      14.5  \n",
       "20     106.1  \n",
       "21     151.0  \n",
       "22     205.3  \n",
       "23     222.8  \n",
       "\n",
       "[24 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_pred.drop(labels=[\"Element\",\"CO_B.E\",\"M-Enth.fus\", \"M-Enth.vap\",\"Enth.fus\",\"Enth.vap\",\"M-Enth.atom\",\"Enth.atom\"], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227028c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "PCA_df_Cu_pred = pd.read_csv('PCA_add_Cu_Pred.csv')\n",
    "PCA_df_Cu_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ab033e",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "combined_df_Cu_pred = pd.concat([x, PCA_df_Cu_pred], axis=1)\n",
    "df_Cu_pred = combined_df_Cu_pred\n",
    "df_Cu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f1814ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5597417 , -0.27655712, -0.28420627, -0.3413    , -0.368865  ,\n",
       "       -0.3629183 , -0.42375222, -0.35245734, -0.4824315 , -0.18251206,\n",
       "       -0.05220822, -0.18783873, -0.32452708, -0.30552435, -0.3315994 ,\n",
       "       -0.44329837, -0.43333125, -0.29186085, -0.08826344, -0.4069565 ,\n",
       "       -0.40530595, -0.32678273, -0.38424173, -0.376215  ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50120201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_params = model.get_params()\n",
    "H_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0a6f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.559742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.276557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.368865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.362918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.423752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.352457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.482432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.182512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.052208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.187839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.324527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.305524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.331599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.443298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.433331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.291861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.088263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.406956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.405306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.326783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.384242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.376215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0  -0.559742\n",
       "1  -0.276557\n",
       "2  -0.284206\n",
       "3  -0.341300\n",
       "4  -0.368865\n",
       "5  -0.362918\n",
       "6  -0.423752\n",
       "7  -0.352457\n",
       "8  -0.482432\n",
       "9  -0.182512\n",
       "10 -0.052208\n",
       "11 -0.187839\n",
       "12 -0.324527\n",
       "13 -0.305524\n",
       "14 -0.331599\n",
       "15 -0.443298\n",
       "16 -0.433331\n",
       "17 -0.291861\n",
       "18 -0.088263\n",
       "19 -0.406956\n",
       "20 -0.405306\n",
       "21 -0.326783\n",
       "22 -0.384242\n",
       "23 -0.376215"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(x)\n",
    "p = pd.DataFrame(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0453bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame converted and saved to 'output_data_CO.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "output_file_CO = 'output_data_CO.xlsx'\n",
    "p.to_excel(output_file_CO, index=False)\n",
    "print(f\"Data frame converted and saved to '{output_file_CO}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7405770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0089510e-02 0.0000000e+00 1.2233958e-02 3.7166211e-01 0.0000000e+00\n",
      " 0.0000000e+00 7.1689521e-04 5.5457252e-01 1.2704945e-04 3.5980050e-04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.5574719e-04 3.1360475e-04\n",
      " 6.2984822e-04 1.5326175e-04 3.8449719e-04 8.7527372e-03 1.1897370e-02\n",
      " 2.6830306e-04 4.1025095e-03 2.9853967e-03 1.2003712e-03 1.0136055e-02\n",
      " 5.7455529e-03 1.8590270e-03 0.0000000e+00 6.4868218e-04 5.0527835e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab02332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.stats.qmc import Sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85fed8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "params = { 'max_depth': np.arange(3,15,1),                     #13\n",
    "           'learning_rate': np.arange(0.01,0.1, 0.01),      #0.325\n",
    "           'subsample': np.arange(0.7, 1, 0.01), \n",
    "           'min_child_weight': np.arange(3,15, 1),\n",
    "           #'colsample_bytree': np.arange(0.99, 1, 0.01),        \n",
    "           #'colsample_bylevel': np.arange(0.99, 1, 0.01),       \n",
    "           'n_estimators': np.arange(200,1000,25),                #450\n",
    "           #'reg_alpha': uniform(1,3),                     #0.8612124738904751\n",
    "           #'reg_lambda': uniform(1,10),                      #115.01455430429743  \n",
    "         }\n",
    "sobol_sequence = Sobol(1)\n",
    "lasso = Lasso()\n",
    "# number of times random search is run\n",
    "n = 50                                             # n=20    #n_iter=50  #cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc630665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 1: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=600, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 1th run - Training: 0.004892764971612064, Test: 0.09366545464596367\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 2: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=250, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 2th run - Training: 0.027309898547676112, Test: 0.09825595658594082\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 3: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=450, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 3th run - Training: 0.005826706751363498, Test: 0.08946413918147254\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 4: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=525, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 4th run - Training: 0.020811693948495604, Test: 0.09225917781429346\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 5: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=14, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=625, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 5th run - Training: 0.006055571434718911, Test: 0.0946474301097817\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 6: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.08, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=375, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 6th run - Training: 0.0016465281879331564, Test: 0.09615228714556019\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 7: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.06999999999999999,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 7th run - Training: 0.001085766181600491, Test: 0.08647470719536295\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 8: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.060000000000000005,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=575, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 8th run - Training: 0.0037099841654566383, Test: 0.08883183772813677\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 9: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=425, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 9th run - Training: 0.0038218096569969306, Test: 0.09032602635929736\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=275, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 10th run - Training: 0.015893058686307103, Test: 0.09370725115531936\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 11: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.060000000000000005,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=650, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 11th run - Training: 0.0013089943166088537, Test: 0.08942743510271303\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 12: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.060000000000000005,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=950, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 12th run - Training: 0.002513776339462379, Test: 0.08473896476829182\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 13: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.060000000000000005,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=950, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 13th run - Training: 0.0008205719181783732, Test: 0.09031804695805998\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 14: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=625, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 14th run - Training: 0.004433487367862477, Test: 0.08508083523881345\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 15: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.060000000000000005,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=675, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 15th run - Training: 0.0026325253208731242, Test: 0.08892745762417911\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 16: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=375, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 16th run - Training: 0.0030588046249543856, Test: 0.0883053442161865\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 17: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=825, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 17th run - Training: 0.025329352364859326, Test: 0.0921913150600779\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 18: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=925, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 18th run - Training: 0.0012174433327845435, Test: 0.09155304691365118\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 19: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.06999999999999999,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=675, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 19th run - Training: 0.002805659987427945, Test: 0.09002827400982553\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 20: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=425, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 20th run - Training: 0.009910489897630647, Test: 0.08942817578470565\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 21: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.08, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 21th run - Training: 0.0013550556746126765, Test: 0.09309370561086514\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 22: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=850, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 22th run - Training: 0.007350135987782655, Test: 0.09058709015716342\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 23: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 23th run - Training: 0.003160666600879353, Test: 0.08916047645012665\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 24: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=650, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 24th run - Training: 0.006179603116077207, Test: 0.09511705382959997\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 25: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=525, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 25th run - Training: 0.007526598183342406, Test: 0.09495441636665636\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 26: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=575, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 26th run - Training: 0.007681792201554936, Test: 0.09621785032960734\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 27: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=450, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 27th run - Training: 0.001946148463019445, Test: 0.08813805961359117\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 28: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=925, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 28th run - Training: 0.004564696431183553, Test: 0.08846351071283196\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 29: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 29th run - Training: 0.011508410340589791, Test: 0.08859082763094553\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 30: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=425, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 30th run - Training: 0.011587430100163054, Test: 0.09520441498736824\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 31: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=975, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 31th run - Training: 0.0038236196475882438, Test: 0.09116455566356409\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 32: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.09, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 32th run - Training: 0.0055089766105112055, Test: 0.0961801956866844\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 33: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=550, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 33th run - Training: 0.0017298950306624946, Test: 0.09135595264127583\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 34: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.06999999999999999,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=850, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 34th run - Training: 0.0007826093870615779, Test: 0.09362112415996844\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 35: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=925, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 35th run - Training: 0.001092623687979109, Test: 0.08990740057065712\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 36: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 36th run - Training: 0.002805702668390063, Test: 0.0904104001162612\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 37: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=825, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 37th run - Training: 0.0013296979842461398, Test: 0.09118336351998588\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 38: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=475, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 38th run - Training: 0.013784259252636214, Test: 0.08855874968673536\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 39: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 39th run - Training: 0.011211052917369301, Test: 0.08926774224533542\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 40: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=525, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 40th run - Training: 0.00531072113902992, Test: 0.09122573788952164\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 41: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=750, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 41th run - Training: 0.001270376947847572, Test: 0.0909041154584206\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 42: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=650, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 42th run - Training: 0.006466330870283957, Test: 0.09113815002038056\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 43: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=950, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 43th run - Training: 0.0012664950909793981, Test: 0.08867954045114888\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 44: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.060000000000000005,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=650, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 44th run - Training: 0.0025662798267443087, Test: 0.08836135964175412\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 45: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=325, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 45th run - Training: 0.00707923078853185, Test: 0.09427297595754693\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 46: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=850, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 46th run - Training: 0.0033059370321966686, Test: 0.09568818084267289\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 47: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=575, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 47th run - Training: 0.0040910169878000625, Test: 0.08590372658298083\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 48: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.04, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=8, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=725, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 48th run - Training: 0.017198352980296313, Test: 0.09226995087507034\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 49: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=575, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 49th run - Training: 0.01115223334715842, Test: 0.09152385648625931\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "Run 50: Best Estimator: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=775, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "RMSE for every 50th run - Training: 0.012086633227288856, Test: 0.08883760747533448\n",
      "Predictions from 50 best RMSE models saved to 'output_data_50_Best_xGBR.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "xgbr = xgb.XGBRegressor(seed=20)\n",
    "average = np.array([0]*30, dtype=np.float64)\n",
    "feature_importances = []\n",
    "\n",
    "nth_run = 1\n",
    "best_models = []\n",
    "rmse_values_test = []\n",
    "rmse_values_train = []\n",
    "avg = 0\n",
    "\n",
    "for i in range(n):   \n",
    "    clf = RandomizedSearchCV(estimator=xgbr,\n",
    "                             param_distributions=params,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             n_iter=30,cv=10,random_state=np.random.RandomState(int(sobol_sequence.random(1)[0] * 2**31)),\n",
    "                             verbose=1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    print(f\"Run {i + 1}: Best Estimator: {clf.best_estimator_}\")\n",
    "    best_models.append(clf.best_estimator_)\n",
    "    \n",
    "    if (i + 1) % nth_run == 0:\n",
    "        # Predictions on test set\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        rmse_values_test.append(rmse_test)\n",
    "        \n",
    "        # Predictions on training set\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        rmse_values_train.append(rmse_train)\n",
    "\n",
    "        print(f\"RMSE for every {nth_run}th run - Training: {rmse_train}, Test: {rmse_test}\")\n",
    "        nth_run += 1\n",
    "    \n",
    "    #average += clf.best_estimator_.feature_importances_\n",
    "    #feature_importances.append(clf.best_estimator_.feature_importances_)\n",
    "#average = average/n\n",
    "#avg = avg/n\n",
    "\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "for i, model in enumerate(best_models):\n",
    "    predictions_df[f'Run_{i+1}'] = model.predict(x)\n",
    "\n",
    "# Save predictions to an Excel file\n",
    "output_file = 'output_data_50_Best_xGBR.xlsx'\n",
    "predictions_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions from 50 best RMSE models saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
